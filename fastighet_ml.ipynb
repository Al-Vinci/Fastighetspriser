{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "date_now = dt.datetime.now()\n",
    "date_now = date_now.strftime(\"%y%m%d\")\n",
    "\n",
    "\n",
    "# Konfiguration av loggning\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filename=f\"fastighet_ml_{date_now}.log\", # Loggfil\n",
    "    filemode=\"a\") # Append-läge\n",
    "\n",
    "conn = sqlite3.connect(\"fastigheter.db\")\n",
    "types = [\"fritidshus\", \"gård\", \"hus\", \"kedjehus\", \"lägenhet\", \"parhus\", \"radhus\", \"tomt_mark\", \"villa\", \"övrigt\"]\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "logging.info(\"Startar hämtning från SQLdatabas\")\n",
    "\n",
    "for typ in types:\n",
    "    table_name = f\"fastighetstyp_{typ}\"\n",
    "    try:\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "        dataframes[typ] = df\n",
    "        logging.info(f\"Hämtade {len(df)} rader från tabellen '{table_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Kunde inte hämta tabellen '{table_name}': {e}\")\n",
    "        logging.error(f\"Kunde inte hämta tabellen '{table_name}': {e}\")\n",
    "\n",
    "\n",
    "# Sätter Biarea till 0 om inget värde finns, då antas den vara 0\n",
    "for typ, df in dataframes.items():\n",
    "    if \"Biarea\" in df.columns:\n",
    "        df[\"Biarea\"] = df[\"Biarea\"].where(df[\"Biarea\"].notna(), 0)\n",
    "        \n",
    "logging.info(\"Sätter NaN-värden i Biarea till 0\")\n",
    "\n",
    "# Formaterar datum efter YYMMDD\n",
    "for typ, df in dataframes.items():\n",
    "    if \"Datum\" in df.columns:\n",
    "        # Konvertera till datetime om det inte redan är det\n",
    "        datum_antal = len(df[\"Datum\"])\n",
    "        df[\"Datum\"] = pd.to_datetime(df[\"Datum\"], errors=\"coerce\")\n",
    "\n",
    "        # Formatera till YYMMDD som sträng\n",
    "        df[\"Datum\"] = df[\"Datum\"].dt.strftime(\"%y%m%d\")\n",
    "\n",
    "        logging.info(f\"{typ}: Datum-kolumnen formaterad till YYMMDD, {datum_antal} st\")\n",
    "    else:\n",
    "        logging.info(f\"{typ}: Ingen 'Datum'-kolumn hittades, ingen formatering gjord\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04dd40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slå ihop kedjehus och parhus till radhus\n",
    "if \"radhus\" in dataframes:\n",
    "    frames_to_add = []\n",
    "    for subtyp in [\"kedjehus\", \"parhus\"]:\n",
    "        if subtyp in dataframes:\n",
    "            frames_to_add.append(dataframes[subtyp])\n",
    "\n",
    "    if frames_to_add:  # bara om något hittades\n",
    "        dataframes[\"radhus\"] = pd.concat(\n",
    "            [dataframes[\"radhus\"]] + frames_to_add,\n",
    "            axis=0,\n",
    "            ignore_index=True)\n",
    "\n",
    "        logging.info(\n",
    "            f\"Slagit ihop {' och '.join(['kedjehus','parhus'])} i 'radhus'. \"\n",
    "            f\"Nytt antal rader: {len(dataframes['radhus'])}\")\n",
    "\n",
    "#Ta bort hus, den innehåller bara skräpdata och kedjehus och parhus som lagts till i radhus. Tar bort övrigt och tomt.\n",
    "del dataframes[\"hus\"]\n",
    "del dataframes[\"kedjehus\"]\n",
    "del dataframes[\"parhus\"]\n",
    "del dataframes[\"övrigt\"]\n",
    "del dataframes[\"tomt_mark\"]\n",
    "logging.info(\"Raderar dataframes, 'hus', 'kedjehus', 'parhus', 'övrigt', 'tomt_mark'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b7b9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gör om nollvärden till NaN i boarea och rum\n",
    "for typ, df in dataframes.items():\n",
    "    if \"Boarea\" in df.columns:\n",
    "        antal_noll = (df[\"Boarea\"] == 0).sum()\n",
    "        df[\"Boarea\"] = df[\"Boarea\"].replace(0, pd.NA)\n",
    "        logging.info(f\"{typ}: {antal_noll} rader med 0 i 'Boarea' ändrades till NaN\")\n",
    "    if \"Rum\" in df.columns:\n",
    "        antal_noll = (df[\"Rum\"] == 0).sum()\n",
    "        df[\"Rum\"] = df[\"Rum\"].replace(0, pd.NA)\n",
    "        logging.info(f\"{typ}: {antal_noll} rader med 0 i 'Rum' ändrades till NaN\")\n",
    "\n",
    "# Tar bort värden som har NaN på både rum och boarea\n",
    "for typ, df in dataframes.items():\n",
    "    if \"Boarea\" in df.columns and \"Rum\" in df.columns:\n",
    "        antal_tomma = df[df[\"Boarea\"].isna() & df[\"Rum\"].isna()].shape[0]\n",
    "        df.dropna(subset=[\"Boarea\", \"Rum\"], how=\"all\", inplace=True)\n",
    "        logging.info(f\"{typ}: {antal_tomma} rader med NaN i både 'Boarea' och 'Rum' tas bort\")\n",
    "    else:\n",
    "        logging.info(f\"{typ}: Kolumnerna 'Boarea' och/eller 'Rum' saknas, inga rader borttagna\")\n",
    "\n",
    "# Tar bort rader med NaN i Tomtarea för villa\n",
    "logging.info(f\"Tar bort {(dataframes['villa']['Tomtarea'].isna()).sum()} rader med NaN-värden från 'Tomtarea' i 'villa'\")\n",
    "dataframes[\"villa\"].dropna(subset=[\"Tomtarea\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868da699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tar bort kolumner då de är irrelevanta eller saknar data\n",
    "dataframes[\"fritidshus\"].drop(columns=\"Våning\", inplace=True) # på ursprungliga objektet\n",
    "dataframes[\"gård\"].drop(columns=\"Våning\", inplace=True) \n",
    "dataframes[\"radhus\"].drop(columns=\"Våning\", inplace=True) \n",
    "dataframes[\"villa\"].drop(columns=\"Våning\", inplace=True) \n",
    "logging.info(\"Tar bort 'Våning' från 'fritidshus', 'gård', 'radhus' och 'villa'\")\n",
    "\n",
    "dataframes[\"lägenhet\"].drop(columns=\"Tomtarea\", inplace=True)\n",
    "dataframes[\"lägenhet\"].drop(columns=\"Biarea\", inplace=True)\n",
    "logging.info(\"Tar bort 'Tomtarea' och 'Biarea' från 'lägenhet'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96670a98",
   "metadata": {},
   "source": [
    "### En modell som uppskattar antal Rum baserat på Boarea och sen en som uppskattar Boarea på antal rum och fyller i NaN värden i Rum och Boarea med prediktioner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c464b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediktera antal rum och ersätt alla NaN värden med prediktion\n",
    "df_villa = dataframes[\"villa\"]\n",
    "\n",
    "# Separera kända och okända värden för 'Boarea'\n",
    "known = df_villa[df_villa[\"Rum\"].notna() & df_villa[\"Boarea\"].notna()].copy()\n",
    "unknown = df_villa[df_villa[\"Rum\"].isna() & df_villa[\"Boarea\"].notna()].copy()\n",
    "\n",
    "logging.info(f\"Antal rader med känt antal rum: {len(known)}\")\n",
    "logging.info(f\"Antal rader med NaN i rum: {len(unknown)}\")\n",
    "\n",
    "# Features = endast boarea\n",
    "X = known[[\"Boarea\"]]\n",
    "y = known[\"Rum\"]\n",
    "\n",
    "# Träna modell\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=11)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "r2_score = model.score(X_test, y_test)\n",
    "logging.info(f\"Tränade RandomForestRegressor för 'Rum' baserat på 'Boarea'. R² på testdata: {r2_score:.3f}\")\n",
    "\n",
    "# Prediktera för okända\n",
    "if not unknown.empty:\n",
    "    predicted_rum = model.predict(unknown[[\"Boarea\"]])\n",
    "    # Avrunda till närmaste halvtal\n",
    "    predicted_rum = np.round(predicted_rum * 2) / 2\n",
    "    # Skriv tillbaka i dataframe\n",
    "    df_villa.loc[df_villa[\"Rum\"].isna() & df_villa[\"Boarea\"].notna(), \"Rum\"] = predicted_rum\n",
    "    logging.info(f\"Fyllde i {len(predicted_rum)} NaN-värden i 'Rum' med predikterade värden (avrundat till halvtal).\")\n",
    "else:\n",
    "    logging.info(\"Inga NaN-värden i 'Rum' att fylla i.\")\n",
    "\n",
    "# Uppdatera i dictionaryn\n",
    "dataframes[\"villa\"] = df_villa\n",
    "\n",
    "# # Prediktera storlek i kvm och ersätt alla NaN värden med prediktion\n",
    "df_villa_kvm = dataframes[\"villa\"]\n",
    "\n",
    "# Separera kända och okända värden för 'Boarea'\n",
    "known_kvm = df_villa_kvm[df_villa_kvm[\"Boarea\"].notna() & df_villa_kvm[\"Rum\"].notna()].copy()\n",
    "unknown_kvm = df_villa_kvm[df_villa_kvm[\"Boarea\"].isna() & df_villa_kvm[\"Rum\"].notna()].copy()\n",
    "\n",
    "logging.info(f\"Antal rader med känd boarea: {len(known_kvm)}\")\n",
    "logging.info(f\"Antal rader med NaN i boarea: {len(unknown_kvm)}\")\n",
    "\n",
    "# Features = endast rum\n",
    "X_kvm = known_kvm[[\"Rum\"]]\n",
    "y_kvm = known_kvm[\"Boarea\"]\n",
    "\n",
    "# Träna modell\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_kvm, y_kvm, test_size=0.2, random_state=11)\n",
    "\n",
    "model_kvm = RandomForestRegressor(n_estimators=200, random_state=11)\n",
    "model_kvm.fit(X_train, y_train)\n",
    "\n",
    "r2_score_kvm = model_kvm.score(X_test, y_test)\n",
    "logging.info(f\"Tränade RandomForestRegressor för 'Boarea' baserat på 'Rum'. R² på testdata: {r2_score_kvm:.3f}\")\n",
    "\n",
    "# Prediktera för okända\n",
    "if not unknown_kvm.empty:\n",
    "    predicted_kvm = model_kvm.predict(unknown_kvm[[\"Rum\"]])\n",
    "    predicted_kvm = np.round(predicted_kvm) # Avrunda till närmaste heltal\n",
    "\n",
    "# Skriv tillbaka i dataframe\n",
    "    df_villa_kvm.loc[df_villa_kvm[\"Boarea\"].isna() & df_villa_kvm[\"Rum\"].notna(), \"Boarea\"] = predicted_kvm\n",
    "\n",
    "    logging.info(f\"Fyllde i {len(predicted_kvm)} NaN-värden i 'Boarea' med predikterade värden (avrundat till heltal).\")\n",
    "else:\n",
    "    logging.info(\"Inga NaN-värden i 'Boarea' att fylla i för villa.\")\n",
    "\n",
    "# Uppdatera i dictionaryn\n",
    "dataframes[\"villa\"] = df_villa_kvm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4f5f2",
   "metadata": {},
   "source": [
    "### Avnänder modellen för villa och itererar över fritidshus, gård och radhus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1685058",
   "metadata": {},
   "outputs": [],
   "source": [
    "for typ in [\"fritidshus\", \"gård\", \"radhus\"]:\n",
    "    df = dataframes[typ]\n",
    "\n",
    "    # Fyll i saknade 'Rum' baserat på 'Boarea'\n",
    "    known_rum = df[df[\"Rum\"].notna() & df[\"Boarea\"].notna()].copy()\n",
    "    unknown_rum = df[df[\"Rum\"].isna() & df[\"Boarea\"].notna()].copy()\n",
    "\n",
    "    logging.info(f\"{typ}: {len(known_rum)} rader med känd boarea\")\n",
    "    logging.info(f\"{typ}: {len(unknown_rum)} rader med NaN i 'Rum'\")\n",
    "\n",
    "    X_rum = known_rum[[\"Boarea\"]]\n",
    "    y_rum = known_rum[\"Rum\"]\n",
    "    r2_rum = model.score(X_rum, y_rum)\n",
    "    logging.info(f\"{typ}: R² för prediktion av 'Rum' från 'Boarea': {r2_rum:.3f}\")\n",
    "\n",
    "    if not unknown_rum.empty:\n",
    "        predicted_rum = model.predict(unknown_rum[[\"Boarea\"]])\n",
    "        predicted_rum = np.round(predicted_rum * 2) / 2\n",
    "        df.loc[df[\"Rum\"].isna() & df[\"Boarea\"].notna(), \"Rum\"] = predicted_rum\n",
    "        logging.info(f\"{typ}: Fyllde i {len(predicted_rum)} saknade 'Rum'-värden\")\n",
    "\n",
    "    # Fyll i saknade 'Boarea' baserat på 'Rum'\n",
    "    known_boarea = df[df[\"Boarea\"].notna() & df[\"Rum\"].notna()].copy()\n",
    "    unknown_boarea = df[df[\"Boarea\"].isna() & df[\"Rum\"].notna()].copy()\n",
    "\n",
    "    logging.info(f\"{typ}: {len(known_boarea)} rader med känt antal rum\")\n",
    "    logging.info(f\"{typ}: {len(unknown_boarea)} rader med NaN i 'Boarea'\")\n",
    "\n",
    "    X_boarea = known_boarea[[\"Rum\"]]\n",
    "    y_boarea = known_boarea[\"Boarea\"]\n",
    "    r2_boarea = model_kvm.score(X_boarea, y_boarea)\n",
    "    logging.info(f\"{typ}: R² för prediktion av 'Boarea' från 'Rum': {r2_boarea:.3f}\")\n",
    "\n",
    "    if not unknown_boarea.empty:\n",
    "        predicted_boarea = model_kvm.predict(unknown_boarea[[\"Rum\"]])\n",
    "        predicted_boarea = np.round(predicted_boarea)\n",
    "        df.loc[df[\"Boarea\"].isna() & df[\"Rum\"].notna(), \"Boarea\"] = predicted_boarea\n",
    "        logging.info(f\"{typ}: Fyllde i {len(predicted_boarea)} saknade 'Boarea'-värden\")\n",
    "\n",
    "    # Uppdaterar dataframen\n",
    "    dataframes[typ] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d82fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Städar upp bland datan\n",
    "# Tar bort rader med NaN i 'Våning' i lägenheter, tillräckligt många datapunkter finns ändå\n",
    "logging.info(f\"lägenhet: Tar bort {(dataframes['lägenhet']['Våning'].isna()).sum()} \"\n",
    "\"rader som har NaN i 'Våning'\")\n",
    "dataframes[\"lägenhet\"].dropna(subset=[\"Våning\"], inplace=True)\n",
    "\n",
    "# Tar bort rader med NaN i 'Boarea' och 'Rum' i 'lägenhet'\n",
    "logging.info(f\"lägenhet: Tar bort {(dataframes['lägenhet']['Boarea'].isna()).sum()} \"\n",
    "\"rader med NaN i 'Boarea'\")\n",
    "dataframes[\"lägenhet\"].dropna(subset=[\"Boarea\"], inplace=True)\n",
    "logging.info(f\"lägenhet: Tar bort {(dataframes['lägenhet']['Rum'].isna()).sum()} \"\n",
    "\"rader med NaN i 'Rum'\")\n",
    "dataframes[\"lägenhet\"].dropna(subset=[\"Rum\"], inplace=True)\n",
    "\n",
    "# Tar bort rader med NaN i 'Tomtarea' i 'gård'\n",
    "logging.info(f\"radhus: Tar bort {(dataframes['gård']['Tomtarea'].isna()).sum()} \"\n",
    "\"rader som har NaN i 'Tomtarea'\")\n",
    "dataframes[\"gård\"].dropna(subset=[\"Tomtarea\"], inplace=True)\n",
    "\n",
    "# Tar bort rader med NaN i 'Tomtarea' i 'radhus'\n",
    "logging.info(f\"radhus: Tar bort {(dataframes['radhus']['Tomtarea'].isna()).sum()} \"\n",
    "\"rader som har NaN i 'Tomtarea'\")\n",
    "dataframes[\"radhus\"].dropna(subset=[\"Tomtarea\"], inplace=True)\n",
    "\n",
    "# Ersätt ',' med '.' och konverterar 'Våning' till numerisk och avrundar\n",
    "dataframes[\"lägenhet\"][\"Våning\"] = dataframes[\"lägenhet\"][\"Våning\"].astype(str).str.replace(\",\", \".\", regex=False)\n",
    "dataframes[\"lägenhet\"][\"Våning\"] = pd.to_numeric(dataframes[\"lägenhet\"][\"Våning\"], errors=\"coerce\")\n",
    "dataframes[\"lägenhet\"][\"Våning\"] = dataframes[\"lägenhet\"][\"Våning\"].round(0).astype(\"Int64\")\n",
    "logging.info(\"Konverterar 'Våning' i 'lägenhet' till numerisk och avrundar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1458c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tar bort decimaler och konverterar till tal\n",
    "for namn, df in dataframes.items():\n",
    "    for kolumn in [\"Tomtarea\", \"Boarea\", \"Biarea\"]:\n",
    "        if kolumn in df.columns:\n",
    "            # Ersätt ',' med '.' och konvertera till numerisk\n",
    "            df[kolumn] = df[kolumn].astype(str).str.replace(\",\", \".\", regex=False)\n",
    "            df[kolumn] = pd.to_numeric(df[kolumn], errors=\"coerce\")\n",
    "            \n",
    "            # Avrunda och konvertera till Int64\n",
    "            df[kolumn] = df[kolumn].round(0).astype(\"Int64\")  # \"Int64\" tål NaN\n",
    "            logging.info(f\"Konverterar '{kolumn}' i '{namn}' till numerisk och avrundar\")\n",
    "\n",
    "    # Skriv tillbaka uppdaterad dataframe\n",
    "    dataframes[namn] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997503e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itererar över alla df och tar bort alla fastigheter där priset avviker mer än \n",
    "# 50% från snittet på gatan för att få bort problem med försäljningar inom familj etc\n",
    "for namn, df in dataframes.items():\n",
    "    if \"Adress\" in df.columns and \"Ort\" in df.columns and \"Pris\" in df.columns:\n",
    "        # Räkna ut medelpris per (Adress, Ort)\n",
    "        mean_prices = df.groupby([\"Adress\", \"Ort\"])[\"Pris\"].transform(\"mean\")\n",
    "\n",
    "        # Mask: vilka rader skiljer sig mer än 50% från snittet\n",
    "        mask_outliers = (df[\"Pris\"] > 1.5 * mean_prices) | (df[\"Pris\"] < 0.5 * mean_prices)\n",
    "        # Räkna hur många som tas bort\n",
    "        antal_bort = mask_outliers.sum()\n",
    "        # Droppa outliers\n",
    "        df = df.loc[~mask_outliers].copy()\n",
    "        # Logga resultat\n",
    "        logging.info(f\"I '{namn}' togs {antal_bort} rader bort då priset skiljde sig mer än 50% från snittet för samma Adress/Ort.\")\n",
    "\n",
    "        # Uppdatera i dictionary\n",
    "        dataframes[namn] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c5118a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6513406\ttest: 0.6483214\tbest: 0.6483214 (0)\ttotal: 253ms\tremaining: 8m 25s\n",
      "100:\tlearn: 0.3850571\ttest: 0.3688453\tbest: 0.3688453 (100)\ttotal: 8.72s\tremaining: 2m 44s\n",
      "200:\tlearn: 0.3769856\ttest: 0.3623147\tbest: 0.3623147 (200)\ttotal: 17.8s\tremaining: 2m 39s\n",
      "300:\tlearn: 0.3720300\ttest: 0.3592303\tbest: 0.3592303 (300)\ttotal: 26.7s\tremaining: 2m 30s\n",
      "400:\tlearn: 0.3678998\ttest: 0.3571904\tbest: 0.3571904 (400)\ttotal: 36.2s\tremaining: 2m 24s\n",
      "500:\tlearn: 0.3642940\ttest: 0.3555797\tbest: 0.3555797 (500)\ttotal: 45.9s\tremaining: 2m 17s\n",
      "600:\tlearn: 0.3612624\ttest: 0.3544194\tbest: 0.3544194 (600)\ttotal: 54.5s\tremaining: 2m 6s\n",
      "700:\tlearn: 0.3585055\ttest: 0.3536507\tbest: 0.3536488 (698)\ttotal: 1m 3s\tremaining: 1m 57s\n",
      "800:\tlearn: 0.3556971\ttest: 0.3528562\tbest: 0.3528562 (800)\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "900:\tlearn: 0.3532176\ttest: 0.3524555\tbest: 0.3524555 (900)\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "1000:\tlearn: 0.3507780\ttest: 0.3520110\tbest: 0.3520094 (999)\ttotal: 1m 32s\tremaining: 1m 31s\n",
      "1100:\tlearn: 0.3484794\ttest: 0.3515188\tbest: 0.3515188 (1100)\ttotal: 1m 40s\tremaining: 1m 22s\n",
      "1200:\tlearn: 0.3463564\ttest: 0.3511894\tbest: 0.3511894 (1200)\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1300:\tlearn: 0.3444029\ttest: 0.3508971\tbest: 0.3508971 (1300)\ttotal: 1m 58s\tremaining: 1m 3s\n",
      "1400:\tlearn: 0.3425478\ttest: 0.3507435\tbest: 0.3507435 (1400)\ttotal: 2m 7s\tremaining: 54.7s\n",
      "1500:\tlearn: 0.3407764\ttest: 0.3505517\tbest: 0.3505517 (1500)\ttotal: 2m 17s\tremaining: 45.6s\n",
      "1600:\tlearn: 0.3389200\ttest: 0.3504058\tbest: 0.3504058 (1600)\ttotal: 2m 26s\tremaining: 36.6s\n",
      "1700:\tlearn: 0.3372332\ttest: 0.3502606\tbest: 0.3502606 (1700)\ttotal: 2m 36s\tremaining: 27.4s\n",
      "1800:\tlearn: 0.3354629\ttest: 0.3501845\tbest: 0.3501671 (1784)\ttotal: 2m 45s\tremaining: 18.3s\n",
      "1900:\tlearn: 0.3336699\ttest: 0.3500514\tbest: 0.3500514 (1900)\ttotal: 2m 54s\tremaining: 9.09s\n",
      "1999:\tlearn: 0.3320795\ttest: 0.3498607\tbest: 0.3498600 (1986)\ttotal: 3m 3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.3498599905\n",
      "bestIteration = 1986\n",
      "\n",
      "Shrink model to first 1987 iterations.\n"
     ]
    }
   ],
   "source": [
    "#Cat boost med logaritmiska priser\n",
    "from sklearn.metrics import r2_score, mean_squared_error # Deklarerar om\n",
    "\n",
    "# Förbered data\n",
    "lower_lg_villa = dataframes[\"villa\"][\"Pris\"].quantile(0.05)\n",
    "upper_lg_villa = dataframes[\"villa\"][\"Pris\"].quantile(0.95)\n",
    "\n",
    "# Filtrera bort outliers\n",
    "df_filtered_lg_villa = dataframes[\"villa\"][(dataframes[\"villa\"][\"Pris\"] > lower_lg_villa) & (dataframes[\"villa\"][\"Pris\"] < upper_lg_villa)].copy()\n",
    "\n",
    "# Skapa log-transformerad target\n",
    "df_filtered_lg_villa[\"log_pris\"] = np.log1p(df_filtered_lg_villa[\"Pris\"])\n",
    "target = \"log_pris\"\n",
    "\n",
    "# Ta bort kolumner som inte ska vara med\n",
    "drop_cols_lg_villa = [col for col in [\"Pris\", \"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\"] if col in df_filtered_lg_villa.columns]\n",
    "\n",
    "X_lg_villa = df_filtered_lg_villa.drop(columns=drop_cols_lg_villa + [target])  # ta bort både Pris och log_pris\n",
    "y_lg_villa = df_filtered_lg_villa[target]\n",
    "\n",
    "# Identifiera kategoriska kolumner\n",
    "cat_features_lg_villa = X_lg_villa.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "logging.info(f\"Kategoriska variabler som används: {cat_features_lg_villa}\")\n",
    "\n",
    "# Train/test split\n",
    "X_lg_villa_train, X_lg_villa_test, y_lg_villa_train, y_lg_villa_test = train_test_split(\n",
    "    X_lg_villa, y_lg_villa, test_size=0.2, random_state=11)\n",
    "\n",
    "# CatBoost-modell\n",
    "model = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    depth=8,\n",
    "    learning_rate=0.0422,\n",
    "    loss_function=\"RMSE\",\n",
    "    cat_features=cat_features_lg_villa,\n",
    "    verbose=100,\n",
    "    bagging_temperature=5,\n",
    "    l2_leaf_reg=5)\n",
    "\n",
    "# Träna modellen\n",
    "model.fit(X_lg_villa_train, y_lg_villa_train, eval_set=(X_lg_villa_test, y_lg_villa_test), use_best_model=True)\n",
    "\n",
    "# Utvärdera\n",
    "y_lg_villa_pred_train = np.expm1(model.predict(X_lg_villa_train))\n",
    "y_lg_villa_pred_test  = np.expm1(model.predict(X_lg_villa_test))\n",
    "\n",
    "r2_train_lg_villa = r2_score(np.expm1(y_lg_villa_train), y_lg_villa_pred_train)\n",
    "r2_test_lg_villa  = r2_score(np.expm1(y_lg_villa_test), y_lg_villa_pred_test)\n",
    "\n",
    "rmse_train_lg_villa = np.sqrt(mean_squared_error(np.expm1(y_lg_villa_train), y_lg_villa_pred_train))\n",
    "rmse_test_lg_villa  = np.sqrt(mean_squared_error(np.expm1(y_lg_villa_test), y_lg_villa_pred_test))\n",
    "\n",
    "logging.info(f\"CatBoost tränad på villa-data med log(pris). \"\n",
    "    f\"R² train: {r2_train_lg_villa:.3f}, test: {r2_test_lg_villa:.3f}, \"\n",
    "    f\"RMSE train: {rmse_train_lg_villa:.0f}, test: {rmse_test_lg_villa:.0f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importances_lg_villa = model.get_feature_importance()\n",
    "feature_names_lg_villa = np.array(X_lg_villa.columns)\n",
    "\n",
    "sorted_idx_lg_villa = feature_importances_lg_villa.argsort()\n",
    "\n",
    "# Logga topp 5 features\n",
    "top_n_lg_villa = 5\n",
    "top_idx_lg_villa = feature_importances_lg_villa.argsort()[::-1][:top_n_lg_villa]\n",
    "top_features_lg_villa = [(feature_names_lg_villa[i], feature_importances_lg_villa[i]) for i in top_idx_lg_villa]\n",
    "\n",
    "logging.info(\"Topp 5 viktigaste features för pris:\")\n",
    "for name, importance in top_features_lg_villa:\n",
    "    logging.info(f\"- {name}: {importance:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127bdb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2027836.7392046\ttest: 2017802.8606597\tbest: 2017802.8606597 (0)\ttotal: 92ms\tremaining: 3m 3s\n",
      "100:\tlearn: 1172561.9879582\ttest: 1123003.9150008\tbest: 1123003.9150008 (100)\ttotal: 8.25s\tremaining: 2m 35s\n",
      "200:\tlearn: 1138684.3662493\ttest: 1092996.5449711\tbest: 1092996.5449711 (200)\ttotal: 17.8s\tremaining: 2m 39s\n",
      "300:\tlearn: 1119839.4045053\ttest: 1081380.3116968\tbest: 1081380.3116968 (300)\ttotal: 26.5s\tremaining: 2m 29s\n",
      "400:\tlearn: 1105188.9548111\ttest: 1074342.3464419\tbest: 1074342.3464419 (400)\ttotal: 35.8s\tremaining: 2m 22s\n",
      "500:\tlearn: 1093438.5275343\ttest: 1069264.2627370\tbest: 1069264.2627370 (500)\ttotal: 44.8s\tremaining: 2m 14s\n",
      "600:\tlearn: 1082314.0933192\ttest: 1065168.3603374\tbest: 1065168.3603374 (600)\ttotal: 54.1s\tremaining: 2m 6s\n",
      "700:\tlearn: 1072329.5001840\ttest: 1062072.1986821\tbest: 1062072.1986821 (700)\ttotal: 1m 4s\tremaining: 1m 58s\n",
      "800:\tlearn: 1064433.6241152\ttest: 1060168.6120755\tbest: 1060162.1682215 (798)\ttotal: 1m 13s\tremaining: 1m 50s\n",
      "900:\tlearn: 1057178.3263359\ttest: 1058202.0466115\tbest: 1058202.0466115 (900)\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "1000:\tlearn: 1049445.5679786\ttest: 1056761.6990623\tbest: 1056761.6990623 (1000)\ttotal: 1m 31s\tremaining: 1m 31s\n",
      "1100:\tlearn: 1041975.2891277\ttest: 1055126.1367236\tbest: 1055111.0809461 (1099)\ttotal: 1m 40s\tremaining: 1m 22s\n",
      "1200:\tlearn: 1034911.5515469\ttest: 1053687.4145941\tbest: 1053684.0426629 (1199)\ttotal: 1m 50s\tremaining: 1m 13s\n",
      "1300:\tlearn: 1028721.6815528\ttest: 1052389.8987334\tbest: 1052386.9700681 (1299)\ttotal: 1m 58s\tremaining: 1m 3s\n",
      "1400:\tlearn: 1022457.2348198\ttest: 1051379.8239315\tbest: 1051379.8239315 (1400)\ttotal: 2m 9s\tremaining: 55.2s\n",
      "1500:\tlearn: 1016983.7806842\ttest: 1050473.3445374\tbest: 1050473.3445374 (1500)\ttotal: 2m 18s\tremaining: 46.1s\n",
      "1600:\tlearn: 1010909.1597338\ttest: 1049446.5780492\tbest: 1049446.5780492 (1600)\ttotal: 2m 27s\tremaining: 36.8s\n",
      "1700:\tlearn: 1005475.0881288\ttest: 1048619.8858058\tbest: 1048586.3834710 (1695)\ttotal: 2m 36s\tremaining: 27.5s\n",
      "1800:\tlearn: 1000021.5455543\ttest: 1047954.5122721\tbest: 1047954.5122721 (1800)\ttotal: 2m 45s\tremaining: 18.3s\n",
      "1900:\tlearn: 994700.6576036\ttest: 1047560.3630193\tbest: 1047560.3630193 (1900)\ttotal: 2m 54s\tremaining: 9.09s\n",
      "1999:\tlearn: 989448.7580828\ttest: 1047044.4577794\tbest: 1047044.4577794 (1999)\ttotal: 3m 3s\tremaining: 0us\n",
      "\n",
      "bestTest = 1047044.458\n",
      "bestIteration = 1999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cat boost med Grid searchade parametrar\n",
    "from sklearn.metrics import r2_score, mean_squared_error # Deklarerar om\n",
    "\n",
    "lower_cb_gs_villa = dataframes[\"villa\"][\"Pris\"].quantile(0.05)\n",
    "upper_cb_gs_villa = dataframes[\"villa\"][\"Pris\"].quantile(0.95)\n",
    "\n",
    "# Filtrera bort rader utanför percentilgränserna\n",
    "df_filtered_cb_gs_villa = dataframes[\"villa\"][(dataframes[\"villa\"][\"Pris\"] > lower_cb_gs_villa) & (dataframes[\"villa\"][\"Pris\"] < upper_cb_gs_villa)]\n",
    "\n",
    "# Välj dataframe\n",
    "df_cb_cb_gs_villa = df_filtered_cb_gs_villa.copy()\n",
    "\n",
    "# Målvariabeln heter 'Pris'\n",
    "target_cb_gs_villa = \"Pris\"\n",
    "\n",
    "# Ta bort \"Datum\" och \"Bostadstyp\" om de finns\n",
    "drop_cols_cb_gs_villa = [col for col in [\"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\"] if col in df_cb_cb_gs_villa.columns]\n",
    "X_cb_gs_villa = df_cb_cb_gs_villa.drop(columns=[target_cb_gs_villa] + drop_cols_cb_gs_villa)\n",
    "y_cb_gs_villa = df_cb_cb_gs_villa[target_cb_gs_villa]\n",
    "\n",
    "# Identifiera kategoriska kolumner\n",
    "cat_features_cb_gs_villa = X_cb_gs_villa.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "logging.info(f\"Kategoriska variabler som används: {cat_features_cb_gs_villa}\")\n",
    "\n",
    "# Train/test split\n",
    "X_cb_gs_villa_train, X_cb_gs_villa_test, y_cb_gs_villa_train, y_cb_gs_villa_test = train_test_split(\n",
    "    X_cb_gs_villa, y_cb_gs_villa, test_size=0.2, random_state=11)\n",
    "\n",
    "# CatBoost-modell\n",
    "model_cb_gs_villa = CatBoostRegressor(\n",
    "    iterations=2000, #5000\n",
    "    depth=8,\n",
    "    learning_rate=0.042222222222222223, #0,01 gav 0,818 o 0,725\n",
    "    loss_function=\"RMSE\",\n",
    "    cat_features=cat_features_cb_gs_villa,\n",
    "    verbose=100,\n",
    "    bagging_temperature=5,\n",
    "    l2_leaf_reg=5)\n",
    "\n",
    "# Träna modellen\n",
    "model_cb_gs_villa.fit(X_cb_gs_villa_train, y_cb_gs_villa_train, eval_set=(X_cb_gs_villa_test, y_cb_gs_villa_test), use_best_model=True)\n",
    "\n",
    "# Utvärdera\n",
    "r2_train_cb_gs_villa = model_cb_gs_villa.score(X_cb_gs_villa_train, y_cb_gs_villa_train)\n",
    "r2_test_cb_gs_villa = model_cb_gs_villa.score(X_cb_gs_villa_test, y_cb_gs_villa_test)\n",
    "\n",
    "# Prediktioner\n",
    "y_pred_train = model_cb_gs_villa.predict(X_cb_gs_villa_train)\n",
    "y_pred_test = model_cb_gs_villa.predict(X_cb_gs_villa_test)\n",
    "\n",
    "# RMSE\n",
    "rmse_train_cb_gs_villa = np.sqrt(mean_squared_error(y_cb_gs_villa_train, y_pred_train))\n",
    "rmse_test_cb_gs_villa = np.sqrt(mean_squared_error(y_cb_gs_villa_test, y_pred_test))\n",
    "\n",
    "# MAPE\n",
    "mape_train_cb_gs_villa = mean_absolute_percentage_error(y_cb_gs_villa_train, y_pred_train) * 100\n",
    "mape_test_cb_gs_villa = mean_absolute_percentage_error(y_cb_gs_villa_test, y_pred_test) * 100\n",
    "\n",
    "logging.info(f\"CatBoost tränad på villa-data. \"\n",
    "    f\"R² train: {r2_train_cb_gs_villa:.3f}, test: {r2_test_cb_gs_villa:.3f}, \"\n",
    "    f\"RMSE train: {rmse_train_cb_gs_villa:.0f}, test: {rmse_test_cb_gs_villa:.0f}\")\n",
    "logging.info(f\"CatBoost MAPE train: {mape_train_cb_gs_villa:.2f}%, test: {mape_test_cb_gs_villa:.2f}%\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importances_cb_gs_villa = model_cb_gs_villa.get_feature_importance()\n",
    "feature_names_cb_gs_villa = np.array(X_cb_gs_villa.columns)\n",
    "\n",
    "# Sortera efter betydelse\n",
    "sorted_idx_cb_gs_villa = feature_importances_cb_gs_villa.argsort()\n",
    "\n",
    "# Logga topp 5 features\n",
    "top_n_cb_gs_villa = 5\n",
    "top_idx_cb_gs_villa = feature_importances_cb_gs_villa.argsort()[::-1][:top_n_cb_gs_villa]  # index på topp N\n",
    "top_features_cb_gs_villa = [(feature_names_cb_gs_villa[i], feature_importances_cb_gs_villa[i]) for i in top_idx_cb_gs_villa]\n",
    "\n",
    "logging.info(\"Topp 5 viktigaste features för pris:\")\n",
    "for name, importance in top_features_cb_gs_villa:\n",
    "    logging.info(f\"- {name}: {importance:.2f}\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump(model_cb_gs_villa, \"villa_cb_gs.pkl\")\n",
    "\n",
    "logging.info(\"Modellen är sparad som 'villa_cb_gs.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61560ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mStartar RandomizedSearchCV för CatBoostRegressor...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Träna\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_gs_villa_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_gs_villa_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Resultat från CV\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(random_search.cv_results_[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Alvin\\anaconda3\\envs\\DS24\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Alvin\\anaconda3\\envs\\DS24\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Alvin\\anaconda3\\envs\\DS24\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Alvin\\anaconda3\\envs\\DS24\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Alvin\\anaconda3\\envs\\DS24\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Alvin\\anaconda3\\envs\\DS24\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Alvin\\anaconda3\\envs\\DS24\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Alvin\\anaconda3\\envs\\DS24\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Randomized search villa\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Filtrera data (exempel med \"villa\")\n",
    "lower_gs_villa = dataframes[\"villa\"][\"Pris\"].quantile(0.05)\n",
    "upper_gs_villa = dataframes[\"villa\"][\"Pris\"].quantile(0.95)\n",
    "df_gs_villa = dataframes[\"villa\"][(dataframes[\"villa\"][\"Pris\"]\n",
    "    > lower_gs_villa) & (dataframes[\"villa\"][\"Pris\"] < upper_gs_villa)].copy()\n",
    "\n",
    "# target_gs_villa\n",
    "target_gs_villa = \"Pris\"\n",
    "\n",
    "# Drop-kolumner (om de finns)\n",
    "drop_cols_gs_villa = [col for col in [\"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\"] if col in df_gs_villa.columns]\n",
    "\n",
    "# Features & target_gs_villa\n",
    "X_gs_villa = df_gs_villa.drop(columns=[target_gs_villa] + drop_cols_gs_villa)\n",
    "y_gs_villa = df_gs_villa[target_gs_villa]\n",
    "\n",
    "# Kategoriska features\n",
    "cat_features_gs_villa = X_gs_villa.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "logging.info(f\"Kategoriska variabler som används: {cat_features_gs_villa}\")\n",
    "\n",
    "# Train/test-split\n",
    "X_gs_villa_train, X_gs_villa_test, y_gs_villa_train, y_gs_villa_test = train_test_split(X_gs_villa, y_gs_villa, test_size=0.2, random_state=11)\n",
    "\n",
    "# Modell\n",
    "cat_model = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    cat_features=cat_features_gs_villa,\n",
    "    verbose=0,\n",
    "    random_state=11)\n",
    "\n",
    "# Parameterutrymme\n",
    "param_dist = {\n",
    "    \"iterations\": [500, 1000, 2000, 3000, 5000],\n",
    "    \"depth\": [4, 6, 8, 10],\n",
    "    \"learning_rate\": np.linspace(0.01, 0.3, 10),\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 7, 10],\n",
    "    \"bagging_temperature\": [0, 0.5, 1, 2, 3, 5]}\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=cat_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=\"neg_root_mean_squared_error\", # Optimera RMSE\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=11,\n",
    "    n_jobs=-1)\n",
    "\n",
    "logging.info(\"Startar RandomizedSearchCV för CatBoostRegressor...\")\n",
    "\n",
    "# Träna\n",
    "random_search.fit(X_gs_villa_train, y_gs_villa_train)\n",
    "\n",
    "# Resultat från CV\n",
    "for i, params in enumerate(random_search.cv_results_[\"params\"]):\n",
    "    mean_score = random_search.cv_results_[\"mean_test_score\"][i]\n",
    "    std_score = random_search.cv_results_[\"std_test_score\"][i]\n",
    "    logging.info(f\"Run {i+1}: Score={mean_score:.4f} (+/- {std_score:.4f}) | Params={params}\")\n",
    "\n",
    "# Bästa resultat\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "logging.info(f\"Bästa parametrar: {best_params}\")\n",
    "logging.info(f\"Bästa RMSE-score (cross val): {best_score:.4f}\")\n",
    "\n",
    "# Träna om bästa modellen\n",
    "best_cat_model = random_search.best_estimator_\n",
    "best_cat_model.fit(X_gs_villa_train, y_gs_villa_train, eval_set=(X_gs_villa_test, y_gs_villa_test), verbose=100)\n",
    "\n",
    "# Utvärdera på testdatan\n",
    "r2_test = best_cat_model.score(X_gs_villa_test, y_gs_villa_test)\n",
    "logging.info(f\"R² på testdata: {r2_test:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "# Filtrera ut extremvärden\n",
    "lower_rf_villa = dataframes[\"villa\"][\"Pris\"].quantile(0.05)\n",
    "upper_rf_villa = dataframes[\"villa\"][\"Pris\"].quantile(0.95)\n",
    "\n",
    "df_filtered_rf_villa = dataframes[\"villa\"][(dataframes[\"villa\"][\"Pris\"]\n",
    "    > lower_rf_villa) & (dataframes[\"villa\"][\"Pris\"] < upper_rf_villa)].copy()\n",
    "\n",
    "# Features & target_rf_villa\n",
    "target_rf_villa = \"Pris\"\n",
    "\n",
    "drop_cols = [col for col in [\"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\", \"Adress\"] if col in df_filtered_rf_villa.columns]\n",
    "X_rf_villa = df_filtered_rf_villa.drop(columns=[target_rf_villa] + drop_cols)\n",
    "y_rf_villa = df_filtered_rf_villa[target_rf_villa]\n",
    "\n",
    "# Gör log-transform på target_rf_villa\n",
    "y_rf_villa_log = np.log1p(y_rf_villa)  # log(Pris + 1) för att undvika log(0)\n",
    "\n",
    "# Gör dummy-variabler för kategoriska features\n",
    "X_rf_villa = pd.get_dummies(X_rf_villa, drop_first=True)\n",
    "\n",
    "# Train/test split\n",
    "X_rf_villa_train, X_rf_villa_test, y_rf_villa_train, y_rf_villa_test = train_test_split(\n",
    "    X_rf_villa, y_rf_villa_log, test_size=0.2, random_state=11)\n",
    "\n",
    "# Definiera modellen\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=15,\n",
    "    random_state=11,\n",
    "    n_jobs=-1)\n",
    "\n",
    "rf_model.fit(X_rf_villa_train, y_rf_villa_train)\n",
    "\n",
    "# Utvärdera modellen\n",
    "y_rf_villa_train_pred = rf_model.predict(X_rf_villa_train)\n",
    "y_rf_villa_test_pred = rf_model.predict(X_rf_villa_test)\n",
    "\n",
    "r2_train_rf_villa = r2_score(y_rf_villa_train, y_rf_villa_train_pred)\n",
    "r2_test_rf_villa = r2_score(y_rf_villa_test, y_rf_villa_test_pred)\n",
    "\n",
    "rmse_train_rf_villa = np.sqrt(mean_squared_error(y_rf_villa_train, y_rf_villa_train_pred))\n",
    "rmse_test_rf_villa = np.sqrt(mean_squared_error(y_rf_villa_test, y_rf_villa_test_pred))\n",
    "\n",
    "logging.info(f\"RF på villa-data. R² train: {r2_train_rf_villa:.3f}, test: {r2_test_rf_villa:.3f}\")\n",
    "logging.info(f\"RF på villa-data. RMSE train: {rmse_train_rf_villa:.3f}, test: {rmse_test_rf_villa:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8daa911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11614\n",
      "[LightGBM] [Info] Number of data points in the train set: 73949, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 14.828778\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.37129\tvalid_0's l2: 0.137856\n",
      "[200]\tvalid_0's rmse: 0.366457\tvalid_0's l2: 0.134291\n",
      "[300]\tvalid_0's rmse: 0.365133\tvalid_0's l2: 0.133322\n",
      "[400]\tvalid_0's rmse: 0.363996\tvalid_0's l2: 0.132493\n",
      "[500]\tvalid_0's rmse: 0.363917\tvalid_0's l2: 0.132436\n",
      "[600]\tvalid_0's rmse: 0.363579\tvalid_0's l2: 0.132189\n",
      "[700]\tvalid_0's rmse: 0.363402\tvalid_0's l2: 0.132061\n",
      "[800]\tvalid_0's rmse: 0.36338\tvalid_0's l2: 0.132045\n",
      "[900]\tvalid_0's rmse: 0.363378\tvalid_0's l2: 0.132044\n",
      "[1000]\tvalid_0's rmse: 0.363341\tvalid_0's l2: 0.132017\n",
      "Early stopping, best iteration is:\n",
      "[947]\tvalid_0's rmse: 0.363324\tvalid_0's l2: 0.132004\n"
     ]
    }
   ],
   "source": [
    "# LGBM model, villa\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Filtrera ut extremvärden\n",
    "lower_lgbm_villa = dataframes[\"villa\"][\"Pris\"].quantile(0.05)\n",
    "upper_lgbm_villa = dataframes[\"villa\"][\"Pris\"].quantile(0.95)\n",
    "\n",
    "df_filtered_lgbm_villa = dataframes[\"villa\"][\n",
    "    (dataframes[\"villa\"][\"Pris\"] > lower_lgbm_villa) & (dataframes[\"villa\"][\"Pris\"] < upper_lgbm_villa)].copy()\n",
    "\n",
    "# Features & target\n",
    "target_lgbm_villa = \"Pris\"\n",
    "drop_cols_lgbm_villa = [col for col in [\"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\"] if col in df_filtered_lgbm_villa.columns]\n",
    "\n",
    "X_lgbm_villa = df_filtered_lgbm_villa.drop(columns=[target_lgbm_villa] + drop_cols_lgbm_villa)\n",
    "y_lgbm_villa = df_filtered_lgbm_villa[target_lgbm_villa]\n",
    "\n",
    "# Log-transformera target_lgbm_villa\n",
    "y_lgbm_villa_log = np.log1p(y_lgbm_villa)\n",
    "\n",
    "\n",
    "# Gör kategoriska kolumner rätt\n",
    "# Konvertera textkolumner till \"category\" innan split\n",
    "for col in X_lgbm_villa.select_dtypes(include=\"object\").columns:\n",
    "    X_lgbm_villa[col] = X_lgbm_villa[col].astype(\"category\")\n",
    "\n",
    "# Train/test split\n",
    "X_lgbm_villa_train, X_lgbm_villa_test, y_lgbm_villa_train, y_lgbm_villa_test = train_test_split(\n",
    "    X_lgbm_villa, y_lgbm_villa_log, test_size=0.2, random_state=11)\n",
    "\n",
    "# Lista index för kategoriska variabler\n",
    "cat_features_lgbm_villa = [X_lgbm_villa_train.columns.get_loc(col) for col in X_lgbm_villa_train.select_dtypes(include=\"category\").columns]\n",
    "\n",
    "logging.info(f\"Kategoriska features: {[X_lgbm_villa_train.columns[i] for i in cat_features_lgbm_villa]}\")\n",
    "\n",
    "\n",
    "# LightGBM modell\n",
    "lgbm_model = LGBMRegressor(\n",
    "    n_estimators=2000,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=11,\n",
    "    n_jobs=-1)\n",
    "\n",
    "lgbm_model.fit(\n",
    "    X_lgbm_villa_train, y_lgbm_villa_train,\n",
    "    eval_set=[(X_lgbm_villa_test, y_lgbm_villa_test)],\n",
    "    eval_metric=\"rmse\",\n",
    "    categorical_feature=cat_features_lgbm_villa,\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=100),\n",
    "        log_evaluation(period=100)])\n",
    "\n",
    "# Utvärdering\n",
    "# Prediktion på log-skalan\n",
    "y_lgbm_villa_train_pred_log = lgbm_model.predict(X_lgbm_villa_train)\n",
    "y_lgbm_villa_test_pred_log = lgbm_model.predict(X_lgbm_villa_test)\n",
    "\n",
    "# R² på log-skala\n",
    "r2_train_lgbm_villa_log_lgbm_villa = r2_score(y_lgbm_villa_train, y_lgbm_villa_train_pred_log)\n",
    "r2_test_lgbm_villa_log_lgbm_villa = r2_score(y_lgbm_villa_test, y_lgbm_villa_test_pred_log)\n",
    "\n",
    "logging.info(f\"Log-skala R² -> train: {r2_train_lgbm_villa_log_lgbm_villa:.3f}, test: {r2_test_lgbm_villa_log_lgbm_villa:.3f}\")\n",
    "\n",
    "# Back-transform till SEK\n",
    "y_lgbm_villa_train_pred = np.expm1(y_lgbm_villa_train_pred_log)\n",
    "y_lgbm_villa_test_pred = np.expm1(y_lgbm_villa_test_pred_log)\n",
    "\n",
    "y_lgbm_villa_train_true = np.expm1(y_lgbm_villa_train)\n",
    "y_lgbm_villa_test_true = np.expm1(y_lgbm_villa_test)\n",
    "\n",
    "# R² och RMSE och MAPE\n",
    "r2_train_lgbm_villa = r2_score(y_lgbm_villa_train_true, y_lgbm_villa_train_pred)\n",
    "r2_test_lgbm_villa = r2_score(y_lgbm_villa_test_true, y_lgbm_villa_test_pred)\n",
    "\n",
    "rmse_train_lgbm_villa = np.sqrt(mean_squared_error(y_lgbm_villa_train_true, y_lgbm_villa_train_pred))\n",
    "rmse_test_lgbm_villa = np.sqrt(mean_squared_error(y_lgbm_villa_test_true, y_lgbm_villa_test_pred))\n",
    "\n",
    "logging.info(f\"LGBM tränad på villa-data R² train: {r2_train_lgbm_villa:.3f}, test: {r2_test_lgbm_villa:.3f}\")\n",
    "logging.info(f\"LGBM tränad på villa-data RMSE train: {rmse_train_lgbm_villa:,.0f}, test: {rmse_test_lgbm_villa:,.0f} kr\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump((lgbm_model, X_lgbm_villa.columns), \"villa_lgbm.pkl\")\n",
    "\n",
    "logging.info(\"Modellen är sparad som 'villa_lgbm.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac2c1e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Nyckel  Våning  Rum  Boarea   Datum     Pris                Adress  \\\n",
      "0   31634       1  2.0      42  250630  1695000  Gamla Lasarettsgatan   \n",
      "1   68573       2  3.0      79  250429  1765000        Gymnastikgatan   \n",
      "3  142883       3  2.0      50  241120  2890000            Bruksgatan   \n",
      "4   13020       2  2.0      55  250805  1712500   John Engellaus gata   \n",
      "5   61959       7  3.0      79  250513  8600000     Slåttervallsgatan   \n",
      "\n",
      "  Bostadstyp                  Område         Ort  Totalarea  \n",
      "0   Lägenhet  Gamla Lasarettsområdet  Norrköping       42.5  \n",
      "1   Lägenhet  Gamla Lasarettsområdet  Norrköping       79.0  \n",
      "3   Lägenhet  Sandarna & Fixfabriken    Göteborg       50.5  \n",
      "4   Lägenhet   Västra Munktellstaden  Eskilstuna       55.0  \n",
      "5   Lägenhet   Norra Djurgårdsstaden   Stockholm       79.0  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33139af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8208\n",
      "[LightGBM] [Info] Number of data points in the train set: 82223, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 14.668723\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's rmse: 0.176914\tvalid_0's l2: 0.0312984\n",
      "[200]\tvalid_0's rmse: 0.171549\tvalid_0's l2: 0.0294289\n",
      "[300]\tvalid_0's rmse: 0.16886\tvalid_0's l2: 0.0285136\n",
      "[400]\tvalid_0's rmse: 0.167038\tvalid_0's l2: 0.0279018\n",
      "[500]\tvalid_0's rmse: 0.165845\tvalid_0's l2: 0.0275046\n",
      "[600]\tvalid_0's rmse: 0.164865\tvalid_0's l2: 0.0271804\n",
      "[700]\tvalid_0's rmse: 0.164294\tvalid_0's l2: 0.0269925\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's rmse: 0.163812\tvalid_0's l2: 0.0268345\n",
      "[900]\tvalid_0's rmse: 0.1633\tvalid_0's l2: 0.0266668\n",
      "[1000]\tvalid_0's rmse: 0.162921\tvalid_0's l2: 0.0265431\n",
      "[1100]\tvalid_0's rmse: 0.16261\tvalid_0's l2: 0.026442\n",
      "[1200]\tvalid_0's rmse: 0.162326\tvalid_0's l2: 0.0263496\n",
      "[1300]\tvalid_0's rmse: 0.162079\tvalid_0's l2: 0.0262695\n",
      "[1400]\tvalid_0's rmse: 0.16192\tvalid_0's l2: 0.0262182\n",
      "[1500]\tvalid_0's rmse: 0.16175\tvalid_0's l2: 0.026163\n",
      "[1600]\tvalid_0's rmse: 0.161598\tvalid_0's l2: 0.0261138\n",
      "[1700]\tvalid_0's rmse: 0.16148\tvalid_0's l2: 0.0260758\n",
      "[1800]\tvalid_0's rmse: 0.16134\tvalid_0's l2: 0.0260305\n",
      "[1900]\tvalid_0's rmse: 0.161231\tvalid_0's l2: 0.0259953\n",
      "[2000]\tvalid_0's rmse: 0.161155\tvalid_0's l2: 0.0259709\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.161155\tvalid_0's l2: 0.0259709\n"
     ]
    }
   ],
   "source": [
    "# LGBM model för lägenhet med GS parametrar\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Filtrera ut extremvärden\n",
    "lower_lgbm_lagenhet = dataframes[\"lägenhet\"][\"Pris\"].quantile(0.05)\n",
    "upper_lgbm_lagenhet = dataframes[\"lägenhet\"][\"Pris\"].quantile(0.95)\n",
    "\n",
    "df_filtered_lgbm_lagenhet = dataframes[\"lägenhet\"][\n",
    "    (dataframes[\"lägenhet\"][\"Pris\"] > lower_lgbm_lagenhet) & (dataframes[\"lägenhet\"][\"Pris\"] < upper_lgbm_lagenhet)].copy()\n",
    "\n",
    "# Features & target\n",
    "target_lgbm_lagenhet = \"Pris\"\n",
    "drop_cols_lgbm_lagenhet = [col for col in [\"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\"] if col in df_filtered_lgbm_lagenhet.columns]\n",
    "\n",
    "X_lgbm_lagenhet = df_filtered_lgbm_lagenhet.drop(columns=[target_lgbm_lagenhet] + drop_cols_lgbm_lagenhet)\n",
    "y_lgbm_lagenhet = df_filtered_lgbm_lagenhet[target_lgbm_lagenhet]\n",
    "\n",
    "# Log-transformera target_lgbm_lagenhet\n",
    "y_lgbm_lagenhet_log = np.log1p(y_lgbm_lagenhet)\n",
    "\n",
    "\n",
    "# Gör kategoriska kolumner rätt\n",
    "# Konvertera textkolumner till \"category\" innan split\n",
    "for col in X_lgbm_lagenhet.select_dtypes(include=\"object\").columns:\n",
    "    X_lgbm_lagenhet[col] = X_lgbm_lagenhet[col].astype(\"category\")\n",
    "\n",
    "# Train/test split\n",
    "X_lgbm_lagenhet_train, X_lgbm_lagenhet_test, y_lgbm_lagenhet_train, y_lgbm_lagenhet_test = train_test_split(\n",
    "    X_lgbm_lagenhet, y_lgbm_lagenhet_log, test_size=0.2, random_state=11)\n",
    "\n",
    "# Lista index för kategoriska variabler\n",
    "cat_features_lgbm_lagenhet = [X_lgbm_lagenhet_train.columns.get_loc(col) for col in X_lgbm_lagenhet_train.select_dtypes(include=\"category\").columns]\n",
    "\n",
    "logging.info(f\"Kategoriska features: {[X_lgbm_lagenhet_train.columns[i] for i in cat_features_lgbm_lagenhet]}\")\n",
    "\n",
    "\n",
    "# LightGBM modell\n",
    "lgbm_model_lagenhet = LGBMRegressor(\n",
    "    n_estimators=2000,\n",
    "    max_depth=10, # 12\n",
    "    learning_rate=0.1, # 0.05\n",
    "    subsample=0.6, #0.8\n",
    "    colsample_bytree=0.6, # 0.8\n",
    "    reg_lambda=10, # 1.0\n",
    "    random_state=11,\n",
    "    n_jobs=-1)\n",
    "\n",
    "lgbm_model_lagenhet.fit(\n",
    "    X_lgbm_lagenhet_train, y_lgbm_lagenhet_train,\n",
    "    eval_set=[(X_lgbm_lagenhet_test, y_lgbm_lagenhet_test)],\n",
    "    eval_metric=\"rmse\",\n",
    "    categorical_feature=cat_features_lgbm_lagenhet,\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=100),\n",
    "        log_evaluation(period=100)])\n",
    "\n",
    "# Utvärdering\n",
    "# Prediktion på log-skalan\n",
    "y_lgbm_lagenhet_train_pred_log = lgbm_model_lagenhet.predict(X_lgbm_lagenhet_train)\n",
    "y_lgbm_lagenhet_test_pred_log = lgbm_model_lagenhet.predict(X_lgbm_lagenhet_test)\n",
    "\n",
    "# R² på log-skala\n",
    "r2_train_lgbm_lagenhet_log_lgbm_lagenhet = r2_score(y_lgbm_lagenhet_train, y_lgbm_lagenhet_train_pred_log)\n",
    "r2_test_lgbm_lagenhet_log_lgbm_lagenhet = r2_score(y_lgbm_lagenhet_test, y_lgbm_lagenhet_test_pred_log)\n",
    "\n",
    "logging.info(f\"Log-skala R² -> train: {r2_train_lgbm_lagenhet_log_lgbm_lagenhet:.3f}, test: {r2_test_lgbm_lagenhet_log_lgbm_lagenhet:.3f}\")\n",
    "\n",
    "# Back-transform till SEK\n",
    "y_lgbm_lagenhet_train_pred = np.expm1(y_lgbm_lagenhet_train_pred_log)\n",
    "y_lgbm_lagenhet_test_pred = np.expm1(y_lgbm_lagenhet_test_pred_log)\n",
    "\n",
    "y_lgbm_lagenhet_train_true = np.expm1(y_lgbm_lagenhet_train)\n",
    "y_lgbm_lagenhet_test_true = np.expm1(y_lgbm_lagenhet_test)\n",
    "\n",
    "# R² och RMSE i SEK\n",
    "r2_train_lgbm_lagenhet = r2_score(y_lgbm_lagenhet_train_true, y_lgbm_lagenhet_train_pred)\n",
    "r2_test_lgbm_lagenhet = r2_score(y_lgbm_lagenhet_test_true, y_lgbm_lagenhet_test_pred)\n",
    "\n",
    "rmse_train_lgbm_lagenhet = np.sqrt(mean_squared_error(y_lgbm_lagenhet_train_true, y_lgbm_lagenhet_train_pred))\n",
    "rmse_test_lgbm_lagenhet = np.sqrt(mean_squared_error(y_lgbm_lagenhet_test_true, y_lgbm_lagenhet_test_pred))\n",
    "\n",
    "logging.info(f\"LGBM tränad på lägenhet-data R² train: {r2_train_lgbm_lagenhet:.3f}, test: {r2_test_lgbm_lagenhet:.3f}\")\n",
    "logging.info(f\"LGBM tränad på lägenhet-data RMSE train: {rmse_train_lgbm_lagenhet:,.0f}, test: {rmse_test_lgbm_lagenhet:,.0f} kr\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump((lgbm_model_lagenhet, X_lgbm_lagenhet.columns), \"lagenhet_lgbm.pkl\")\n",
    "\n",
    "logging.info(\"Modellen är sparad som 'lagenhet_lgbm.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "697fe72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1620 candidates, totalling 4860 fits\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8208\n",
      "[LightGBM] [Info] Number of data points in the train set: 82223, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 14.668723\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8208\n",
      "[LightGBM] [Info] Number of data points in the train set: 82223, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 14.668723\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's rmse: 0.176914\tvalid_0's l2: 0.0312984\n",
      "[200]\tvalid_0's rmse: 0.171549\tvalid_0's l2: 0.0294289\n",
      "[300]\tvalid_0's rmse: 0.16886\tvalid_0's l2: 0.0285136\n",
      "[400]\tvalid_0's rmse: 0.167038\tvalid_0's l2: 0.0279018\n",
      "[500]\tvalid_0's rmse: 0.165845\tvalid_0's l2: 0.0275046\n",
      "[600]\tvalid_0's rmse: 0.164865\tvalid_0's l2: 0.0271804\n",
      "[700]\tvalid_0's rmse: 0.164294\tvalid_0's l2: 0.0269925\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's rmse: 0.163812\tvalid_0's l2: 0.0268345\n",
      "[900]\tvalid_0's rmse: 0.1633\tvalid_0's l2: 0.0266668\n",
      "[1000]\tvalid_0's rmse: 0.162921\tvalid_0's l2: 0.0265431\n",
      "[1100]\tvalid_0's rmse: 0.16261\tvalid_0's l2: 0.026442\n",
      "[1200]\tvalid_0's rmse: 0.162326\tvalid_0's l2: 0.0263496\n",
      "[1300]\tvalid_0's rmse: 0.162079\tvalid_0's l2: 0.0262695\n",
      "[1400]\tvalid_0's rmse: 0.16192\tvalid_0's l2: 0.0262182\n",
      "[1500]\tvalid_0's rmse: 0.16175\tvalid_0's l2: 0.026163\n",
      "[1600]\tvalid_0's rmse: 0.161598\tvalid_0's l2: 0.0261138\n",
      "[1700]\tvalid_0's rmse: 0.16148\tvalid_0's l2: 0.0260758\n",
      "[1800]\tvalid_0's rmse: 0.16134\tvalid_0's l2: 0.0260305\n",
      "[1900]\tvalid_0's rmse: 0.161231\tvalid_0's l2: 0.0259953\n",
      "[2000]\tvalid_0's rmse: 0.161155\tvalid_0's l2: 0.0259709\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.161155\tvalid_0's l2: 0.0259709\n"
     ]
    }
   ],
   "source": [
    "# Grid search lgbm lägenhet\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Definiera parameterutrymme\n",
    "param_grid = {\n",
    "    \"n_estimators\": [1000, 2000, 3000],\n",
    "    \"max_depth\": [6, 8, 10, 12, -1],   # -1 = ingen begränsning\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"reg_lambda\": [0, 1, 5, 10]}\n",
    "\n",
    "# Basmodell\n",
    "lgbm_base = LGBMRegressor(\n",
    "    random_state=11,\n",
    "    n_jobs=-1)\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgbm_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",  # Optimera RMSE\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1)\n",
    "\n",
    "logging.info(\"Startar GridSearchCV för LGBM...\")\n",
    "\n",
    "grid_search.fit(\n",
    "    X_lgbm_lagenhet_train,\n",
    "    y_lgbm_lagenhet_train,\n",
    "    categorical_feature=cat_features_lgbm_lagenhet)\n",
    "\n",
    "# Bästa parametrar\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "logging.info(f\"Bästa parametrar: {best_params}\")\n",
    "logging.info(f\"Bästa CV-score (RMSE): {best_score:.4f}\")\n",
    "\n",
    "# Träna om bästa modellen på hela träningsdatan\n",
    "best_lgbm_model = grid_search.best_estimator_\n",
    "best_lgbm_model.fit(\n",
    "    X_lgbm_lagenhet_train,\n",
    "    y_lgbm_lagenhet_train,\n",
    "    eval_set=[(X_lgbm_lagenhet_test, y_lgbm_lagenhet_test)],\n",
    "    eval_metric=\"rmse\",\n",
    "    categorical_feature=cat_features_lgbm_lagenhet,\n",
    "    callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=100)])\n",
    "\n",
    "# Utvärdering på test\n",
    "y_pred_test_log = best_lgbm_model.predict(X_lgbm_lagenhet_test)\n",
    "y_pred_test = np.expm1(y_pred_test_log)\n",
    "y_true_test = np.expm1(y_lgbm_lagenhet_test)\n",
    "\n",
    "r2_test = r2_score(y_true_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_true_test, y_pred_test))\n",
    "\n",
    "logging.info(f\"Bästa LGBM R² test: {r2_test:.3f}\")\n",
    "logging.info(f\"Bästa LGBM RMSE test: {rmse_test:,.0f} kr\")\n",
    "\n",
    "# Spara bästa modell\n",
    "joblib.dump((best_lgbm_model, X_lgbm_lagenhet.columns), \"lagenhet_lgbm_best.pkl\")\n",
    "logging.info(\"Bästa modellen är sparad som 'lagenhet_lgbm_best.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c546f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1270382.2465881\ttest: 1286212.2441417\tbest: 1286212.2441417 (0)\ttotal: 112ms\tremaining: 3m 44s\n",
      "100:\tlearn: 500145.5428937\ttest: 469316.8376135\tbest: 469316.8376135 (100)\ttotal: 11s\tremaining: 3m 26s\n",
      "200:\tlearn: 466765.7845243\ttest: 445541.3509018\tbest: 445541.3509018 (200)\ttotal: 21.7s\tremaining: 3m 14s\n",
      "300:\tlearn: 443837.5009824\ttest: 432740.6277687\tbest: 432740.6277687 (300)\ttotal: 33.4s\tremaining: 3m 8s\n",
      "400:\tlearn: 428336.3092626\ttest: 425319.6955994\tbest: 425319.6955994 (400)\ttotal: 44.2s\tremaining: 2m 56s\n",
      "500:\tlearn: 415508.8589952\ttest: 420140.9770264\tbest: 420140.9770264 (500)\ttotal: 55s\tremaining: 2m 44s\n",
      "600:\tlearn: 404477.4632128\ttest: 416262.8730167\tbest: 416262.8730167 (600)\ttotal: 1m 5s\tremaining: 2m 33s\n",
      "700:\tlearn: 393440.0157354\ttest: 412906.8572493\tbest: 412906.8572493 (700)\ttotal: 1m 17s\tremaining: 2m 22s\n",
      "800:\tlearn: 384242.6190253\ttest: 410721.5143266\tbest: 410721.5143266 (800)\ttotal: 1m 28s\tremaining: 2m 12s\n",
      "900:\tlearn: 375752.1184114\ttest: 408642.6880783\tbest: 408636.0410861 (899)\ttotal: 1m 40s\tremaining: 2m 2s\n",
      "1000:\tlearn: 368919.7460908\ttest: 407482.7094557\tbest: 407443.2764804 (999)\ttotal: 1m 50s\tremaining: 1m 50s\n",
      "1100:\tlearn: 361681.2569133\ttest: 406311.4995156\tbest: 406311.4995156 (1100)\ttotal: 2m 1s\tremaining: 1m 39s\n",
      "1200:\tlearn: 356000.9781485\ttest: 405674.6869326\tbest: 405674.6869326 (1200)\ttotal: 2m 12s\tremaining: 1m 27s\n",
      "1300:\tlearn: 350542.2639945\ttest: 404953.1552037\tbest: 404945.9963710 (1296)\ttotal: 2m 22s\tremaining: 1m 16s\n",
      "1400:\tlearn: 344521.8412043\ttest: 404121.6378124\tbest: 404121.6378124 (1400)\ttotal: 2m 34s\tremaining: 1m 5s\n",
      "1500:\tlearn: 338969.6386632\ttest: 403463.5972652\tbest: 403463.5638021 (1496)\ttotal: 2m 46s\tremaining: 55.3s\n",
      "1600:\tlearn: 333958.7023317\ttest: 403079.7276990\tbest: 403079.7276990 (1600)\ttotal: 2m 57s\tremaining: 44.2s\n",
      "1700:\tlearn: 329086.4012618\ttest: 402607.9495112\tbest: 402607.9495112 (1700)\ttotal: 3m 8s\tremaining: 33.1s\n",
      "1800:\tlearn: 324591.2211687\ttest: 402159.9364862\tbest: 402156.5394901 (1799)\ttotal: 3m 18s\tremaining: 22s\n",
      "1900:\tlearn: 320318.2911702\ttest: 401636.4593429\tbest: 401614.2348612 (1898)\ttotal: 3m 29s\tremaining: 10.9s\n",
      "1999:\tlearn: 316095.8381757\ttest: 401303.1686225\tbest: 401303.1686225 (1999)\ttotal: 3m 40s\tremaining: 0us\n",
      "\n",
      "bestTest = 401303.1686\n",
      "bestIteration = 1999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cat boost med randomized-searchade parametrar, lägenhet\n",
    "from sklearn.metrics import r2_score, mean_squared_error # Deklarerar om\n",
    "\n",
    "lower_cb_lagenhet = dataframes[\"lägenhet\"][\"Pris\"].quantile(0.05)\n",
    "upper_cb_lagenhet = dataframes[\"lägenhet\"][\"Pris\"].quantile(0.95)\n",
    "\n",
    "# Filtrera bort rader utanför percentilgränserna\n",
    "df_filtered_cb_lagenhet = dataframes[\"lägenhet\"][(dataframes[\"lägenhet\"][\"Pris\"] > lower_cb_lagenhet) & (dataframes[\"lägenhet\"][\"Pris\"] < upper_cb_lagenhet)]\n",
    "\n",
    "# Välj dataframe\n",
    "df_cb_lagenhet = df_filtered_cb_lagenhet.copy()\n",
    "\n",
    "# Målvariabeln heter 'Pris'\n",
    "target_cb_lagenhet = \"Pris\"\n",
    "\n",
    "# Ta bort \"Datum\" och \"Bostadstyp\" om de finns\n",
    "drop_cols_cb_lagenhet = [col for col in [\"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\"] if col in df_cb_lagenhet.columns]\n",
    "X_cb_lagenhet = df_cb_lagenhet.drop(columns=[target_cb_lagenhet] + drop_cols_cb_lagenhet)\n",
    "y_cb_lagenhet = df_cb_lagenhet[target_cb_lagenhet]\n",
    "\n",
    "# Identifiera kategoriska kolumner\n",
    "cat_features_cb_lagenhet = X_cb_lagenhet.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "logging.info(f\"Kategoriska variabler som används: {cat_features_cb_lagenhet}\")\n",
    "\n",
    "# Train/test split\n",
    "X_cb_lagenhet_train, X_cb_lagenhet_test, y_cb_lagenhet_train, y_cb_lagenhet_test = train_test_split(\n",
    "    X_cb_lagenhet, y_cb_lagenhet, test_size=0.2, random_state=11)\n",
    "\n",
    "# CatBoost-modell\n",
    "model_cb_lagenhet = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    depth=10,\n",
    "    learning_rate=0.1,\n",
    "    loss_function=\"RMSE\",\n",
    "    cat_features=cat_features_cb_lagenhet,\n",
    "    verbose=100,\n",
    "    bagging_temperature=0.25,\n",
    "    l2_leaf_reg=7)\n",
    "\n",
    "# Träna modellen\n",
    "model_cb_lagenhet.fit(X_cb_lagenhet_train, y_cb_lagenhet_train, eval_set=(X_cb_lagenhet_test, y_cb_lagenhet_test), use_best_model=True)\n",
    "\n",
    "# Utvärdera\n",
    "r2_train_cb_lagenhet = model_cb_lagenhet.score(X_cb_lagenhet_train, y_cb_lagenhet_train)\n",
    "r2_test_cb_lagenhet = model_cb_lagenhet.score(X_cb_lagenhet_test, y_cb_lagenhet_test)\n",
    "\n",
    "# Prediktioner\n",
    "y_pred_train_cb_lagenhet = model_cb_lagenhet.predict(X_cb_lagenhet_train)\n",
    "y_pred_test_cb_lagenhet = model_cb_lagenhet.predict(X_cb_lagenhet_test)\n",
    "\n",
    "# RMSE\n",
    "rmse_train_cb_lagenhet = np.sqrt(mean_squared_error(y_cb_lagenhet_train, y_pred_train_cb_lagenhet))\n",
    "rmse_test_cb_lagenhet = np.sqrt(mean_squared_error(y_cb_lagenhet_test, y_pred_test_cb_lagenhet))\n",
    "\n",
    "logging.info(f\"CatBoost tränad på lägenhet-data. \"\n",
    "    f\"R² train: {r2_train_cb_lagenhet:.3f}, test: {r2_test_cb_lagenhet:.3f}, \"\n",
    "    f\"RMSE train: {rmse_train_cb_lagenhet:.0f}, test: {rmse_test_cb_lagenhet:.0f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importances_cb_lagenhet = model_cb_lagenhet.get_feature_importance()\n",
    "feature_names_cb_lagenhet = np.array(X_cb_lagenhet.columns)\n",
    "\n",
    "# Sortera efter betydelse\n",
    "sorted_idx_cb_lagenhet = feature_importances_cb_lagenhet.argsort()\n",
    "\n",
    "# Logga topp 5 features\n",
    "top_n_cb_lagenhet = 5\n",
    "top_idx_cb_lagenhet = feature_importances_cb_lagenhet.argsort()[::-1][:top_n_cb_lagenhet]  # index på topp N\n",
    "top_features_cb_lagenhet = [(feature_names_cb_lagenhet[i], feature_importances_cb_lagenhet[i]) for i in top_idx_cb_lagenhet]\n",
    "\n",
    "logging.info(\"Topp 5 viktigaste features för pris:\")\n",
    "for name, importance in top_features_cb_lagenhet:\n",
    "    logging.info(f\"- {name}: {importance:.2f}\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump(model_cb_lagenhet, \"lagenhet_cb.pkl\")\n",
    "\n",
    "logging.info(\"Modellen är sparad som 'lagenhet_cb.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1996d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "0:\tlearn: 1248948.0809594\ttest: 1261540.1712568\tbest: 1261540.1712568 (0)\ttotal: 133ms\tremaining: 4m 26s\n",
      "100:\tlearn: 497330.5301038\ttest: 465227.1123951\tbest: 465227.1123951 (100)\ttotal: 11.7s\tremaining: 3m 40s\n",
      "200:\tlearn: 463656.6606406\ttest: 441045.4945333\tbest: 441045.4945333 (200)\ttotal: 23.5s\tremaining: 3m 30s\n",
      "300:\tlearn: 443275.7575992\ttest: 429745.7049866\tbest: 429741.3288174 (299)\ttotal: 34.7s\tremaining: 3m 15s\n",
      "400:\tlearn: 427454.2216338\ttest: 422777.5933362\tbest: 422777.5933362 (400)\ttotal: 45.6s\tremaining: 3m 1s\n",
      "500:\tlearn: 415894.3526547\ttest: 418192.4985290\tbest: 418192.4985290 (500)\ttotal: 56.8s\tremaining: 2m 50s\n",
      "600:\tlearn: 405059.9073004\ttest: 414960.6493344\tbest: 414960.6493344 (600)\ttotal: 1m 7s\tremaining: 2m 37s\n",
      "700:\tlearn: 394538.1767363\ttest: 412228.2540381\tbest: 412228.2540381 (700)\ttotal: 1m 19s\tremaining: 2m 26s\n",
      "800:\tlearn: 385736.3835858\ttest: 410143.1062782\tbest: 410124.4069893 (798)\ttotal: 1m 30s\tremaining: 2m 15s\n",
      "900:\tlearn: 376713.0995502\ttest: 408297.6807724\tbest: 408297.6807724 (900)\ttotal: 1m 41s\tremaining: 2m 3s\n",
      "1000:\tlearn: 369033.0283201\ttest: 406925.9962493\tbest: 406925.9962493 (1000)\ttotal: 1m 52s\tremaining: 1m 52s\n",
      "1100:\tlearn: 361973.0662033\ttest: 405941.7982622\tbest: 405941.0932142 (1095)\ttotal: 2m 3s\tremaining: 1m 40s\n",
      "1200:\tlearn: 355495.9099700\ttest: 405077.1947804\tbest: 405077.1947804 (1200)\ttotal: 2m 14s\tremaining: 1m 29s\n",
      "1300:\tlearn: 349891.6600209\ttest: 404255.2520991\tbest: 404244.2472804 (1299)\ttotal: 2m 25s\tremaining: 1m 18s\n",
      "1400:\tlearn: 344526.7300937\ttest: 403701.3312586\tbest: 403701.3312586 (1400)\ttotal: 2m 37s\tremaining: 1m 7s\n",
      "1500:\tlearn: 339659.6270405\ttest: 403284.7648221\tbest: 403228.9152278 (1488)\ttotal: 2m 48s\tremaining: 55.9s\n",
      "1600:\tlearn: 334832.5516315\ttest: 402755.9905099\tbest: 402740.4085875 (1595)\ttotal: 2m 58s\tremaining: 44.6s\n",
      "1700:\tlearn: 330086.4510719\ttest: 402500.7200097\tbest: 402456.6489548 (1670)\ttotal: 3m 9s\tremaining: 33.3s\n",
      "1800:\tlearn: 325586.6619124\ttest: 402144.2113099\tbest: 402106.7446556 (1789)\ttotal: 3m 20s\tremaining: 22.2s\n",
      "1900:\tlearn: 320908.2868541\ttest: 401811.7521786\tbest: 401811.7521786 (1900)\ttotal: 3m 31s\tremaining: 11s\n",
      "1999:\tlearn: 317291.2322575\ttest: 401469.2638120\tbest: 401468.4101683 (1998)\ttotal: 3m 41s\tremaining: 0us\n",
      "\n",
      "bestTest = 401468.4102\n",
      "bestIteration = 1998\n",
      "\n",
      "Shrink model to first 1999 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Randomized search för CB lägenhet\n",
    "# Definiera parameterutrymme\n",
    "param_dist = {\n",
    "    \"depth\": [4, 6, 8, 10],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 7, 10],\n",
    "    \"bagging_temperature\": [0.25, 1, 2, 5, 10],\n",
    "    \"iterations\": [500, 1000, 2000]}  # early stopping gör att vi inte alltid kör klart\n",
    "\n",
    "# Basmodell\n",
    "cb_base = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    cat_features=cat_features_cb_lagenhet,\n",
    "    verbose=0,  # Stäng av spam under sökning\n",
    "    random_state=11)\n",
    "\n",
    "# Randomized Search\n",
    "random_search_cb = RandomizedSearchCV(\n",
    "    estimator=cb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # antal slumpade kombinationer\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=11)\n",
    "\n",
    "logging.info(\"Startar RandomizedSearchCV för CatBoost...\")\n",
    "\n",
    "# Fit modellen\n",
    "random_search_cb.fit(\n",
    "    X_cb_lagenhet_train, y_cb_lagenhet_train,\n",
    "    eval_set=(X_cb_lagenhet_test, y_cb_lagenhet_test),\n",
    "    use_best_model=True)\n",
    "\n",
    "# Bästa parametrar\n",
    "best_params_cb = random_search_cb.best_params_\n",
    "best_score_cb = random_search_cb.best_score_\n",
    "\n",
    "logging.info(f\"Bästa CatBoost-parametrar: {best_params_cb}\")\n",
    "logging.info(f\"Bästa CV-score (RMSE): {best_score_cb:.4f}\")\n",
    "\n",
    "# Träna om bästa modellen\n",
    "best_cb_model = random_search_cb.best_estimator_\n",
    "best_cb_model.fit(\n",
    "    X_cb_lagenhet_train, y_cb_lagenhet_train,\n",
    "    eval_set=(X_cb_lagenhet_test, y_cb_lagenhet_test),\n",
    "    use_best_model=True,\n",
    "    verbose=100)\n",
    "\n",
    "# Utvärdera på test\n",
    "r2_train_cb = best_cb_model.score(X_cb_lagenhet_train, y_cb_lagenhet_train)\n",
    "r2_test_cb = best_cb_model.score(X_cb_lagenhet_test, y_cb_lagenhet_test)\n",
    "\n",
    "logging.info(f\"Bästa CatBoost R² train: {r2_train_cb:.3f}, test: {r2_test_cb:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b32d206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2049\n",
      "[LightGBM] [Info] Number of data points in the train set: 8348, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 14.226108\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.535205\tvalid_0's l2: 0.286444\n",
      "[200]\tvalid_0's rmse: 0.49155\tvalid_0's l2: 0.241621\n",
      "[300]\tvalid_0's rmse: 0.475459\tvalid_0's l2: 0.226061\n",
      "[400]\tvalid_0's rmse: 0.469301\tvalid_0's l2: 0.220243\n",
      "[500]\tvalid_0's rmse: 0.466483\tvalid_0's l2: 0.217606\n",
      "[600]\tvalid_0's rmse: 0.465124\tvalid_0's l2: 0.216341\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\tvalid_0's rmse: 0.464548\tvalid_0's l2: 0.215805\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's rmse: 0.464448\tvalid_0's l2: 0.215712\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\tvalid_0's rmse: 0.464398\tvalid_0's l2: 0.215666\n",
      "Early stopping, best iteration is:\n",
      "[876]\tvalid_0's rmse: 0.464342\tvalid_0's l2: 0.215613\n"
     ]
    }
   ],
   "source": [
    "# LGBM model för fritidshus med randomized searchade parametrar\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Filtrera ut extremvärden\n",
    "lower_lgbm_fritidshus = dataframes[\"fritidshus\"][\"Pris\"].quantile(0.05)\n",
    "upper_lgbm_fritidshus = dataframes[\"fritidshus\"][\"Pris\"].quantile(0.95)\n",
    "\n",
    "df_filtered_lgbm_fritidshus = dataframes[\"fritidshus\"][\n",
    "    (dataframes[\"fritidshus\"][\"Pris\"] > lower_lgbm_fritidshus) & (dataframes[\"fritidshus\"][\"Pris\"] < upper_lgbm_fritidshus)].copy()\n",
    "\n",
    "# Features & target\n",
    "target_lgbm_fritidshus = \"Pris\"\n",
    "drop_cols_lgbm_fritidshus = [col for col in [\"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\"] if col in df_filtered_lgbm_fritidshus.columns]\n",
    "\n",
    "X_lgbm_fritidshus = df_filtered_lgbm_fritidshus.drop(columns=[target_lgbm_fritidshus] + drop_cols_lgbm_fritidshus)\n",
    "y_lgbm_fritidshus = df_filtered_lgbm_fritidshus[target_lgbm_fritidshus]\n",
    "\n",
    "# Log-transformera target_lgbm_fritidshus\n",
    "y_lgbm_fritidshus_log = np.log1p(y_lgbm_fritidshus)\n",
    "\n",
    "\n",
    "# Gör kategoriska kolumner rätt\n",
    "# Konvertera textkolumner till \"category\" innan split\n",
    "for col in X_lgbm_fritidshus.select_dtypes(include=\"object\").columns:\n",
    "    X_lgbm_fritidshus[col] = X_lgbm_fritidshus[col].astype(\"category\")\n",
    "\n",
    "# Train/test split\n",
    "X_lgbm_fritidshus_train, X_lgbm_fritidshus_test, y_lgbm_fritidshus_train, y_lgbm_fritidshus_test = train_test_split(\n",
    "    X_lgbm_fritidshus, y_lgbm_fritidshus_log, test_size=0.2, random_state=11)\n",
    "\n",
    "# Lista index för kategoriska variabler\n",
    "cat_features_lgbm_fritidshus = [X_lgbm_fritidshus_train.columns.get_loc(col) for col in X_lgbm_fritidshus_train.select_dtypes(include=\"category\").columns]\n",
    "\n",
    "logging.info(f\"Kategoriska features: {[X_lgbm_fritidshus_train.columns[i] for i in cat_features_lgbm_fritidshus]}\")\n",
    "\n",
    "\n",
    "# LightGBM modell\n",
    "lgbm_model_fritidshus = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.01,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=0.6,\n",
    "    reg_lambda=10,\n",
    "    random_state=11,\n",
    "    n_jobs=-1)\n",
    "\n",
    "lgbm_model_fritidshus.fit(\n",
    "    X_lgbm_fritidshus_train, y_lgbm_fritidshus_train,\n",
    "    eval_set=[(X_lgbm_fritidshus_test, y_lgbm_fritidshus_test)],\n",
    "    eval_metric=\"rmse\",\n",
    "    categorical_feature=cat_features_lgbm_fritidshus,\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=100),\n",
    "        log_evaluation(period=100)])\n",
    "\n",
    "# Utvärdering\n",
    "# Prediktion på log-skalan\n",
    "y_lgbm_fritidshus_train_pred_log = lgbm_model_fritidshus.predict(X_lgbm_fritidshus_train)\n",
    "y_lgbm_fritidshus_test_pred_log = lgbm_model_fritidshus.predict(X_lgbm_fritidshus_test)\n",
    "\n",
    "# R² på log-skala\n",
    "r2_train_lgbm_fritidshus_log_lgbm_fritidshus = r2_score(y_lgbm_fritidshus_train, y_lgbm_fritidshus_train_pred_log)\n",
    "r2_test_lgbm_fritidshus_log_lgbm_fritidshus = r2_score(y_lgbm_fritidshus_test, y_lgbm_fritidshus_test_pred_log)\n",
    "\n",
    "logging.info(f\"Log-skala R² -> train: {r2_train_lgbm_fritidshus_log_lgbm_fritidshus:.3f}, test: {r2_test_lgbm_fritidshus_log_lgbm_fritidshus:.3f}\")\n",
    "\n",
    "# Back-transform till SEK\n",
    "y_lgbm_fritidshus_train_pred = np.expm1(y_lgbm_fritidshus_train_pred_log)\n",
    "y_lgbm_fritidshus_test_pred = np.expm1(y_lgbm_fritidshus_test_pred_log)\n",
    "\n",
    "y_lgbm_fritidshus_train_true = np.expm1(y_lgbm_fritidshus_train)\n",
    "y_lgbm_fritidshus_test_true = np.expm1(y_lgbm_fritidshus_test)\n",
    "\n",
    "# R² och RMSE i SEK\n",
    "r2_train_lgbm_fritidshus = r2_score(y_lgbm_fritidshus_train_true, y_lgbm_fritidshus_train_pred)\n",
    "r2_test_lgbm_fritidshus = r2_score(y_lgbm_fritidshus_test_true, y_lgbm_fritidshus_test_pred)\n",
    "\n",
    "rmse_train_lgbm_fritidshus = np.sqrt(mean_squared_error(y_lgbm_fritidshus_train_true, y_lgbm_fritidshus_train_pred))\n",
    "rmse_test_lgbm_fritidshus = np.sqrt(mean_squared_error(y_lgbm_fritidshus_test_true, y_lgbm_fritidshus_test_pred))\n",
    "\n",
    "logging.info(f\"LGBM tränad på fritidshus-data R² train: {r2_train_lgbm_fritidshus:.3f}, test: {r2_test_lgbm_fritidshus:.3f}\")\n",
    "logging.info(f\"LGBM tränad på fritidshus-data RMSE train: {rmse_train_lgbm_fritidshus:,.0f}, test: {rmse_test_lgbm_fritidshus:,.0f} kr\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump((lgbm_model_fritidshus, X_lgbm_fritidshus.columns), \"fritidshus_lgbm.pkl\")\n",
    "\n",
    "logging.info(\"Modellen är sparad som 'fritidshus_lgbm.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0161fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2049\n",
      "[LightGBM] [Info] Number of data points in the train set: 8348, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 14.226108\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2049\n",
      "[LightGBM] [Info] Number of data points in the train set: 8348, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 14.226108\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.535205\tvalid_0's l2: 0.286444\n",
      "[200]\tvalid_0's rmse: 0.49155\tvalid_0's l2: 0.241621\n",
      "[300]\tvalid_0's rmse: 0.475459\tvalid_0's l2: 0.226061\n",
      "[400]\tvalid_0's rmse: 0.469301\tvalid_0's l2: 0.220243\n",
      "[500]\tvalid_0's rmse: 0.466483\tvalid_0's l2: 0.217606\n",
      "[600]\tvalid_0's rmse: 0.465124\tvalid_0's l2: 0.216341\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\tvalid_0's rmse: 0.464548\tvalid_0's l2: 0.215805\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's rmse: 0.464448\tvalid_0's l2: 0.215712\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\tvalid_0's rmse: 0.464398\tvalid_0's l2: 0.215666\n",
      "Early stopping, best iteration is:\n",
      "[876]\tvalid_0's rmse: 0.464342\tvalid_0's l2: 0.215613\n"
     ]
    }
   ],
   "source": [
    "# Randomized search LGBM fritidshus\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Definiera parameterutrymme\n",
    "param_dist = {\n",
    "    \"n_estimators\": [500, 1000, 2000, 3000],\n",
    "    \"max_depth\": [6, 8, 10, 12, -1],   # -1 = ingen begränsning\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"reg_lambda\": [0, 1, 5, 10]}\n",
    "\n",
    "# Basmodell\n",
    "lgbm_base_fritidshus = LGBMRegressor(random_state=11, n_jobs=-1)\n",
    "\n",
    "# Randomized Search\n",
    "random_search_lgbm_fritidshus = RandomizedSearchCV(\n",
    "    estimator=lgbm_base_fritidshus,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,   # antal kombinationer att testa\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=11)\n",
    "\n",
    "logging.info(\"Startar RandomizedSearchCV för LGBM (fritidshus)...\")\n",
    "\n",
    "# Kör sökning\n",
    "random_search_lgbm_fritidshus.fit(\n",
    "    X_lgbm_fritidshus_train, y_lgbm_fritidshus_train,\n",
    "    categorical_feature=cat_features_lgbm_fritidshus)\n",
    "\n",
    "# Bästa parametrar\n",
    "best_params_fritidshus = random_search_lgbm_fritidshus.best_params_\n",
    "best_score_fritidshus = random_search_lgbm_fritidshus.best_score_\n",
    "\n",
    "logging.info(f\"Bästa LGBM-parametrar (fritidshus): {best_params_fritidshus}\")\n",
    "logging.info(f\"Bästa CV-score (RMSE, log-skala): {best_score_fritidshus:.4f}\")\n",
    "\n",
    "# Träna om bästa modellen på hela träningsdatan\n",
    "best_lgbm_fritidshus = random_search_lgbm_fritidshus.best_estimator_\n",
    "best_lgbm_fritidshus.fit(\n",
    "    X_lgbm_fritidshus_train, y_lgbm_fritidshus_train,\n",
    "    eval_set=[(X_lgbm_fritidshus_test, y_lgbm_fritidshus_test)],\n",
    "    eval_metric=\"rmse\",\n",
    "    categorical_feature=cat_features_lgbm_fritidshus,\n",
    "    callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=100)])\n",
    "\n",
    "# Utvärdera på test\n",
    "y_test_pred_log = best_lgbm_fritidshus.predict(X_lgbm_fritidshus_test)\n",
    "y_test_pred = np.expm1(y_test_pred_log)\n",
    "y_test_true = np.expm1(y_lgbm_fritidshus_test)\n",
    "\n",
    "r2_test = r2_score(y_test_true, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_true, y_test_pred))\n",
    "\n",
    "logging.info(f\"Bästa LGBM R² test (fritidshus): {r2_test:.3f}\")\n",
    "logging.info(f\"Bästa LGBM RMSE test (fritidshus): {rmse_test:,.0f} kr\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump((best_lgbm_fritidshus, X_lgbm_fritidshus.columns), \"fritidshus_lgbm_best.pkl\")\n",
    "logging.info(\"Bästa modellen är sparad som 'fritidshus_lgbm_best.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95e198e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1127191.8185402\ttest: 1117557.0613531\tbest: 1117557.0613531 (0)\ttotal: 39.5ms\tremaining: 39.4s\n",
      "100:\tlearn: 838217.7313457\ttest: 822687.7241297\tbest: 822687.7241297 (100)\ttotal: 4.16s\tremaining: 37s\n",
      "200:\tlearn: 818256.3878541\ttest: 813561.3682400\tbest: 813561.3682400 (200)\ttotal: 7.94s\tremaining: 31.6s\n",
      "300:\tlearn: 800904.0907475\ttest: 808126.7412364\tbest: 808022.6264001 (296)\ttotal: 11.9s\tremaining: 27.5s\n",
      "400:\tlearn: 785658.1717243\ttest: 804042.9208790\tbest: 804042.9208790 (400)\ttotal: 15.7s\tremaining: 23.5s\n",
      "500:\tlearn: 772088.9365895\ttest: 802552.1658008\tbest: 802441.9279216 (498)\ttotal: 19.6s\tremaining: 19.5s\n",
      "600:\tlearn: 759871.8053485\ttest: 800255.1668322\tbest: 800247.2666139 (599)\ttotal: 23.5s\tremaining: 15.6s\n",
      "700:\tlearn: 749171.8761364\ttest: 799955.8911928\tbest: 799619.0982075 (645)\ttotal: 27.4s\tremaining: 11.7s\n",
      "800:\tlearn: 739926.2632814\ttest: 800467.5549465\tbest: 799619.0982075 (645)\ttotal: 31.2s\tremaining: 7.75s\n",
      "900:\tlearn: 731730.5352962\ttest: 799678.3689549\tbest: 799564.7748943 (894)\ttotal: 35s\tremaining: 3.84s\n",
      "999:\tlearn: 724204.3359162\ttest: 800180.9982137\tbest: 799564.7748943 (894)\ttotal: 39s\tremaining: 0us\n",
      "\n",
      "bestTest = 799564.7749\n",
      "bestIteration = 894\n",
      "\n",
      "Shrink model to first 895 iterations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Catboost med randomized-searchade parametrar, fritidshus\n",
    "from sklearn.metrics import r2_score, mean_squared_error # Deklarerar om\n",
    "\n",
    "lower_cb_fritidshus = dataframes[\"fritidshus\"][\"Pris\"].quantile(0.05)\n",
    "upper_cb_fritidshus = dataframes[\"fritidshus\"][\"Pris\"].quantile(0.95)\n",
    "\n",
    "# Filtrera bort rader utanför percentilgränserna\n",
    "df_filtered_cb_fritidshus = dataframes[\"fritidshus\"][(dataframes[\"fritidshus\"][\"Pris\"] > lower_cb_fritidshus) & (dataframes[\"fritidshus\"][\"Pris\"] < upper_cb_fritidshus)]\n",
    "\n",
    "# Välj dataframe\n",
    "df_cb_fritidshus = df_filtered_cb_fritidshus.copy()\n",
    "\n",
    "# Målvariabeln heter 'Pris'\n",
    "target_cb_fritidshus = \"Pris\"\n",
    "\n",
    "# Ta bort \"Datum\" och \"Bostadstyp\" om de finns\n",
    "drop_cols_cb_fritidshus = [col for col in [\"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\"] if col in df_cb_fritidshus.columns]\n",
    "X_cb_fritidshus = df_cb_fritidshus.drop(columns=[target_cb_fritidshus] + drop_cols_cb_fritidshus)\n",
    "y_cb_fritidshus = df_cb_fritidshus[target_cb_fritidshus]\n",
    "\n",
    "# Identifiera kategoriska kolumner\n",
    "cat_features_cb_fritidshus = X_cb_fritidshus.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "logging.info(f\"Kategoriska variabler som används: {cat_features_cb_fritidshus}\")\n",
    "\n",
    "# Train/test split\n",
    "X_cb_fritidshus_train, X_cb_fritidshus_test, y_cb_fritidshus_train, y_cb_fritidshus_test = train_test_split(\n",
    "    X_cb_fritidshus, y_cb_fritidshus, test_size=0.2, random_state=11)\n",
    "\n",
    "# CatBoost-modell\n",
    "model_cb_fritidshus = CatBoostRegressor(\n",
    "    iterations=1000, # 3000\n",
    "    depth=6, # 10\n",
    "    learning_rate=0.05, # 0.1\n",
    "    loss_function=\"RMSE\",\n",
    "    cat_features=cat_features_cb_fritidshus,\n",
    "    verbose=100,\n",
    "    bagging_temperature=3, # 0.5\n",
    "    l2_leaf_reg=5) # 10\n",
    "\n",
    "# Träna modellen\n",
    "model_cb_fritidshus.fit(X_cb_fritidshus_train, y_cb_fritidshus_train, eval_set=(X_cb_fritidshus_test, y_cb_fritidshus_test), use_best_model=True)\n",
    "\n",
    "# Utvärdera\n",
    "r2_train_cb_fritidshus = model_cb_fritidshus.score(X_cb_fritidshus_train, y_cb_fritidshus_train)\n",
    "r2_test_cb_fritidshus = model_cb_fritidshus.score(X_cb_fritidshus_test, y_cb_fritidshus_test)\n",
    "\n",
    "# Prediktion\n",
    "y_pred_train_cb_fritidshus = model_cb_fritidshus.predict(X_cb_fritidshus_train)\n",
    "y_pred_test_cb_fritidshus = model_cb_fritidshus.predict(X_cb_fritidshus_test)\n",
    "\n",
    "# RMSE\n",
    "rmse_train_cb_fritidshus = np.sqrt(mean_squared_error(y_cb_fritidshus_train, y_pred_train_cb_fritidshus))\n",
    "rmse_test_cb_fritidshus = np.sqrt(mean_squared_error(y_cb_fritidshus_test, y_pred_test_cb_fritidshus))\n",
    "\n",
    "logging.info(f\"CatBoost tränad på fritidshus-data. \"\n",
    "    f\"R² train: {r2_train_cb_fritidshus:.3f}, test: {r2_test_cb_fritidshus:.3f}, \"\n",
    "    f\"RMSE train: {rmse_train_cb_fritidshus:.0f}, test: {rmse_test_cb_fritidshus:.0f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importances_cb_fritidshus = model_cb_fritidshus.get_feature_importance()\n",
    "feature_names_cb_fritidshus = np.array(X_cb_fritidshus.columns)\n",
    "\n",
    "# Sortera efter betydelse\n",
    "sorted_idx_cb_fritidshus = feature_importances_cb_fritidshus.argsort()\n",
    "\n",
    "# Logga topp 5 features\n",
    "top_n_cb_fritidshus = 5\n",
    "top_idx_cb_fritidshus = feature_importances_cb_fritidshus.argsort()[::-1][:top_n_cb_fritidshus]  # index på topp N\n",
    "top_features_cb_fritidshus = [(feature_names_cb_fritidshus[i], feature_importances_cb_fritidshus[i]) for i in top_idx_cb_fritidshus]\n",
    "\n",
    "logging.info(\"Topp 5 viktigaste features för pris:\")\n",
    "for name, importance in top_features_cb_fritidshus:\n",
    "    logging.info(f\"- {name}: {importance:.2f}\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump(model_cb_fritidshus, \"fritidshus_cb.pkl\")\n",
    "\n",
    "logging.info(\"Modellen är sparad som 'fritidshus_cb.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33862acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "# Randomized search för catboost fritidshus\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Identifiera kategoriska kolumner för fritidshus\n",
    "cat_features_cb_fritidshus = X_cb_fritidshus.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "logging.info(f\"Kategoriska variabler för fritidshus: {cat_features_cb_fritidshus}\")\n",
    "\n",
    "# Definiera parameterutrymme för CatBoost\n",
    "param_dist_cb_fritidshus = {\n",
    "    \"depth\": [6, 8, 10],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"iterations\": [1000, 2000, 3000],\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 10],\n",
    "    \"bagging_temperature\": [0.5, 1, 3, 5]}\n",
    "\n",
    "# Basmodell\n",
    "cb_base_fritidshus = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    cat_features=cat_features_cb_fritidshus,\n",
    "    verbose=0,\n",
    "    random_state=11)\n",
    "\n",
    "# Randomized Search\n",
    "random_search_cb_fritidshus = RandomizedSearchCV(\n",
    "    estimator=cb_base_fritidshus,\n",
    "    param_distributions=param_dist_cb_fritidshus,\n",
    "    n_iter=20,   # slumpade kombinationer\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=11)\n",
    "\n",
    "logging.info(\"Startar RandomizedSearchCV för CatBoost (fritidshus)...\")\n",
    "\n",
    "# Kör sökning\n",
    "random_search_cb_fritidshus.fit(X_cb_fritidshus_train, y_cb_fritidshus_train)\n",
    "\n",
    "# Bästa parametrar\n",
    "best_params_cb_fritidshus = random_search_cb_fritidshus.best_params_\n",
    "best_score_cb_fritidshus = random_search_cb_fritidshus.best_score_\n",
    "\n",
    "logging.info(f\"Bästa CatBoost-parametrar (fritidshus): {best_params_cb_fritidshus}\")\n",
    "logging.info(f\"Bästa CV-score (RMSE): {best_score_cb_fritidshus:.4f}\")\n",
    "\n",
    "# Träna om bästa modellen på hela träningsdatan\n",
    "best_cb_model_fritidshus = random_search_cb_fritidshus.best_estimator_\n",
    "best_cb_model_fritidshus.fit(\n",
    "    X_cb_fritidshus_train, y_cb_fritidshus_train,\n",
    "    eval_set=(X_cb_fritidshus_test, y_cb_fritidshus_test),\n",
    "    use_best_model=True)\n",
    "\n",
    "# Utvärdera på test\n",
    "y_test_pred_cb_fritidshus = best_cb_model_fritidshus.predict(X_cb_fritidshus_test)\n",
    "r2_test_cb_fritidshus = r2_score(y_cb_fritidshus_test, y_test_pred_cb_fritidshus)\n",
    "rmse_test_cb_fritidshus = np.sqrt(mean_squared_error(y_cb_fritidshus_test, y_test_pred_cb_fritidshus))\n",
    "\n",
    "logging.info(f\"Bästa CatBoost (fritidshus) R² test: {r2_test_cb_fritidshus:.3f}\")\n",
    "logging.info(f\"Bästa CatBoost (fritidshus) RMSE test: {rmse_test_cb_fritidshus:,.0f} kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0064a9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1484920.2218664\ttest: 1497017.5020515\tbest: 1497017.5020515 (0)\ttotal: 48.3ms\tremaining: 2m 24s\n",
      "100:\tlearn: 876211.1272137\ttest: 834671.8316998\tbest: 834671.8316998 (100)\ttotal: 5.3s\tremaining: 2m 32s\n",
      "200:\tlearn: 832789.4593476\ttest: 793420.7414320\tbest: 793420.7414320 (200)\ttotal: 10.5s\tremaining: 2m 25s\n",
      "300:\tlearn: 811512.7475461\ttest: 777433.6129536\tbest: 777433.6129536 (300)\ttotal: 17.8s\tremaining: 2m 39s\n",
      "400:\tlearn: 795449.6611924\ttest: 768163.8024804\tbest: 768163.8024804 (400)\ttotal: 24.6s\tremaining: 2m 39s\n",
      "500:\tlearn: 780118.3026005\ttest: 761983.4026823\tbest: 761983.4026823 (500)\ttotal: 31.7s\tremaining: 2m 38s\n",
      "600:\tlearn: 765636.2676380\ttest: 757078.7407562\tbest: 757078.7407562 (600)\ttotal: 39.1s\tremaining: 2m 36s\n",
      "700:\tlearn: 752434.5159236\ttest: 753123.1800517\tbest: 753123.1800517 (700)\ttotal: 46.5s\tremaining: 2m 32s\n",
      "800:\tlearn: 739384.7608354\ttest: 749885.4107893\tbest: 749885.4107893 (800)\ttotal: 54.5s\tremaining: 2m 29s\n",
      "900:\tlearn: 726356.6626614\ttest: 746201.6595875\tbest: 746201.6595875 (900)\ttotal: 1m 2s\tremaining: 2m 24s\n",
      "1000:\tlearn: 713925.5554420\ttest: 743738.8955204\tbest: 743727.3479181 (993)\ttotal: 1m 9s\tremaining: 2m 18s\n",
      "1100:\tlearn: 702263.3716484\ttest: 741817.6269569\tbest: 741817.6269569 (1100)\ttotal: 1m 14s\tremaining: 2m 8s\n",
      "1200:\tlearn: 691301.4418429\ttest: 739979.2349250\tbest: 739966.9465229 (1197)\ttotal: 1m 21s\tremaining: 2m 1s\n",
      "1300:\tlearn: 681508.6401955\ttest: 738552.3462459\tbest: 738550.8526322 (1299)\ttotal: 1m 28s\tremaining: 1m 55s\n",
      "1400:\tlearn: 672460.1043298\ttest: 736905.9486338\tbest: 736905.9486338 (1400)\ttotal: 1m 34s\tremaining: 1m 47s\n",
      "1500:\tlearn: 663664.2830266\ttest: 736112.5538409\tbest: 736106.9397816 (1498)\ttotal: 1m 40s\tremaining: 1m 40s\n",
      "1600:\tlearn: 655317.2175655\ttest: 734919.3225972\tbest: 734895.9086968 (1592)\ttotal: 1m 45s\tremaining: 1m 32s\n",
      "1700:\tlearn: 647056.9002985\ttest: 734141.9638822\tbest: 734021.9946275 (1693)\ttotal: 1m 52s\tremaining: 1m 25s\n",
      "1800:\tlearn: 638954.8565284\ttest: 733561.8968192\tbest: 733528.0203831 (1795)\ttotal: 1m 58s\tremaining: 1m 19s\n",
      "1900:\tlearn: 630660.6245900\ttest: 732863.9928399\tbest: 732863.9928399 (1900)\ttotal: 2m 4s\tremaining: 1m 11s\n",
      "2000:\tlearn: 622795.6237961\ttest: 731999.2306439\tbest: 731995.3551574 (1999)\ttotal: 2m 10s\tremaining: 1m 4s\n",
      "2100:\tlearn: 616092.4406600\ttest: 731685.4226374\tbest: 731659.3485858 (2097)\ttotal: 2m 15s\tremaining: 58.2s\n",
      "2200:\tlearn: 608844.4070786\ttest: 731378.0437585\tbest: 731337.2962954 (2173)\ttotal: 2m 21s\tremaining: 51.5s\n",
      "2300:\tlearn: 601874.9626449\ttest: 730710.0774432\tbest: 730696.5904335 (2288)\ttotal: 2m 27s\tremaining: 44.8s\n",
      "2400:\tlearn: 595447.1056529\ttest: 730299.0401042\tbest: 730271.4533907 (2384)\ttotal: 2m 33s\tremaining: 38.2s\n",
      "2500:\tlearn: 589808.1876991\ttest: 729922.3564243\tbest: 729859.4881889 (2496)\ttotal: 2m 39s\tremaining: 31.7s\n",
      "2600:\tlearn: 583318.8514393\ttest: 729302.5597038\tbest: 729273.5176587 (2590)\ttotal: 2m 44s\tremaining: 25.3s\n",
      "2700:\tlearn: 578056.0596469\ttest: 729137.6988072\tbest: 729056.2395862 (2697)\ttotal: 2m 51s\tremaining: 19s\n",
      "2800:\tlearn: 572317.3847937\ttest: 728738.4063265\tbest: 728738.4063265 (2800)\ttotal: 2m 57s\tremaining: 12.6s\n",
      "2900:\tlearn: 566072.0155661\ttest: 728820.4825116\tbest: 728701.5411764 (2843)\ttotal: 3m 3s\tremaining: 6.25s\n",
      "2999:\tlearn: 559887.0176870\ttest: 728740.4778226\tbest: 728661.6065580 (2972)\ttotal: 3m 9s\tremaining: 0us\n",
      "\n",
      "bestTest = 728661.6066\n",
      "bestIteration = 2972\n",
      "\n",
      "Shrink model to first 2973 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Catboost med randomized-searchade parametrar, radhus\n",
    "from sklearn.metrics import r2_score, mean_squared_error # Deklarerar om\n",
    "\n",
    "lower_cb_radhus = dataframes[\"radhus\"][\"Pris\"].quantile(0.05)\n",
    "upper_cb_radhus = dataframes[\"radhus\"][\"Pris\"].quantile(0.95)\n",
    "\n",
    "# Filtrera bort rader utanför percentilgränserna\n",
    "df_filtered_cb_radhus = dataframes[\"radhus\"][(dataframes[\"radhus\"][\"Pris\"] > lower_cb_radhus) & (dataframes[\"radhus\"][\"Pris\"] < upper_cb_radhus)]\n",
    "\n",
    "# Välj dataframe\n",
    "df_cb_radhus = df_filtered_cb_radhus.copy()\n",
    "\n",
    "# Målvariabeln heter 'Pris'\n",
    "target_cb_radhus = \"Pris\"\n",
    "\n",
    "# Ta bort \"Datum\" och \"Bostadstyp\" om de finns\n",
    "drop_cols_cb_radhus = [col for col in [\"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\"] if col in df_cb_radhus.columns]\n",
    "X_cb_radhus = df_cb_radhus.drop(columns=[target_cb_radhus] + drop_cols_cb_radhus)\n",
    "y_cb_radhus = df_cb_radhus[target_cb_radhus]\n",
    "\n",
    "# Identifiera kategoriska kolumner\n",
    "cat_features_cb_radhus = X_cb_radhus.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "logging.info(f\"Kategoriska variabler som används: {cat_features_cb_radhus}\")\n",
    "\n",
    "# Train/test split\n",
    "X_cb_radhus_train, X_cb_radhus_test, y_cb_radhus_train, y_cb_radhus_test = train_test_split(\n",
    "    X_cb_radhus, y_cb_radhus, test_size=0.2, random_state=11)\n",
    "\n",
    "# CatBoost-modell\n",
    "model_cb_radhus = CatBoostRegressor(\n",
    "    iterations=3000, # 1000\n",
    "    depth=8, # 6\n",
    "    learning_rate=0.03, # 0.3\n",
    "    loss_function=\"RMSE\",\n",
    "    cat_features=cat_features_cb_radhus,\n",
    "    verbose=100,\n",
    "    bagging_temperature=5, # 3\n",
    "    l2_leaf_reg=5) # 10\n",
    "\n",
    "# Träna modellen\n",
    "model_cb_radhus.fit(X_cb_radhus_train, y_cb_radhus_train, eval_set=(X_cb_radhus_test, y_cb_radhus_test), use_best_model=True)\n",
    "\n",
    "# Utvärdera\n",
    "r2_train_cb_radhus = model_cb_radhus.score(X_cb_radhus_train, y_cb_radhus_train)\n",
    "r2_test_cb_radhus = model_cb_radhus.score(X_cb_radhus_test, y_cb_radhus_test)\n",
    "\n",
    "# Prediktion\n",
    "y_pred_train_cb_radhus = model_cb_radhus.predict(X_cb_radhus_train)\n",
    "y_pred_test_cb_radhus = model_cb_radhus.predict(X_cb_radhus_test)\n",
    "\n",
    "# RMSE\n",
    "rmse_train_cb_radhus = np.sqrt(mean_squared_error(y_cb_radhus_train, y_pred_train_cb_radhus))\n",
    "rmse_test_cb_radhus = np.sqrt(mean_squared_error(y_cb_radhus_test, y_pred_test_cb_radhus))\n",
    "\n",
    "logging.info(f\"CatBoost tränad på radhus-data. \"\n",
    "    f\"R² train: {r2_train_cb_radhus:.3f}, test: {r2_test_cb_radhus:.3f}, \"\n",
    "    f\"RMSE train: {rmse_train_cb_radhus:.0f}, test: {rmse_test_cb_radhus:.0f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importances_cb_radhus = model_cb_radhus.get_feature_importance()\n",
    "feature_names_cb_radhus = np.array(X_cb_radhus.columns)\n",
    "\n",
    "# Sortera efter betydelse\n",
    "sorted_idx_cb_radhus = feature_importances_cb_radhus.argsort()\n",
    "\n",
    "# Logga topp 5 features\n",
    "top_n_cb_radhus = 5\n",
    "top_idx_cb_radhus = feature_importances_cb_radhus.argsort()[::-1][:top_n_cb_radhus]  # index på topp N\n",
    "top_features_cb_radhus = [(feature_names_cb_radhus[i], feature_importances_cb_radhus[i]) for i in top_idx_cb_radhus]\n",
    "\n",
    "logging.info(\"Topp 5 viktigaste features för pris:\")\n",
    "for name, importance in top_features_cb_radhus:\n",
    "    logging.info(f\"- {name}: {importance:.2f}\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump(model_cb_radhus, \"radhus_cb.pkl\")\n",
    "\n",
    "logging.info(\"Modellen är sparad som 'radhus_cb.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d71d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "# Randomized search för catboost radhus\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Identifiera kategoriska kolumner för radhus\n",
    "cat_features_cb_radhus = X_cb_radhus.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "logging.info(f\"Kategoriska variabler för radhus: {cat_features_cb_radhus}\")\n",
    "\n",
    "# Definiera parameterutrymme för CatBoost\n",
    "param_dist_cb_radhus = {\n",
    "    \"depth\": [6, 8, 10],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"iterations\": [1000, 2000, 3000],\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 10],\n",
    "    \"bagging_temperature\": [0.5, 1, 3, 5]}\n",
    "\n",
    "# Basmodell\n",
    "cb_base_radhus = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    cat_features=cat_features_cb_radhus,\n",
    "    verbose=0,\n",
    "    random_state=11)\n",
    "\n",
    "# Randomized Search\n",
    "random_search_cb_radhus = RandomizedSearchCV(\n",
    "    estimator=cb_base_radhus,\n",
    "    param_distributions=param_dist_cb_radhus,\n",
    "    n_iter=20,   # slumpade kombinationer\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=11)\n",
    "\n",
    "logging.info(\"Startar RandomizedSearchCV för CatBoost (radhus)...\")\n",
    "\n",
    "# Kör sökning\n",
    "random_search_cb_radhus.fit(X_cb_radhus_train, y_cb_radhus_train)\n",
    "\n",
    "# Bästa parametrar\n",
    "best_params_cb_radhus = random_search_cb_radhus.best_params_\n",
    "best_score_cb_radhus = random_search_cb_radhus.best_score_\n",
    "\n",
    "logging.info(f\"Bästa CatBoost-parametrar (radhus): {best_params_cb_radhus}\")\n",
    "logging.info(f\"Bästa CV-score (RMSE): {best_score_cb_radhus:.4f}\")\n",
    "\n",
    "# Träna om bästa modellen på hela träningsdatan\n",
    "best_cb_model_radhus = random_search_cb_radhus.best_estimator_\n",
    "best_cb_model_radhus.fit(\n",
    "    X_cb_radhus_train, y_cb_radhus_train,\n",
    "    eval_set=(X_cb_radhus_test, y_cb_radhus_test),\n",
    "    use_best_model=True)\n",
    "\n",
    "# Utvärdera på test\n",
    "y_test_pred_cb_radhus = best_cb_model_radhus.predict(X_cb_radhus_test)\n",
    "r2_test_cb_radhus = r2_score(y_cb_radhus_test, y_test_pred_cb_radhus)\n",
    "rmse_test_cb_radhus = np.sqrt(mean_squared_error(y_cb_radhus_test, y_test_pred_cb_radhus))\n",
    "\n",
    "logging.info(f\"Bästa CatBoost (radhus) R² test: {r2_test_cb_radhus:.3f}\")\n",
    "logging.info(f\"Bästa CatBoost (radhus) RMSE test: {rmse_test_cb_radhus:,.0f} kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92aeba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3204\n",
      "[LightGBM] [Info] Number of data points in the train set: 11822, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 15.100396\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.230208\tvalid_0's l2: 0.0529957\n",
      "[200]\tvalid_0's rmse: 0.224041\tvalid_0's l2: 0.0501945\n",
      "[300]\tvalid_0's rmse: 0.222703\tvalid_0's l2: 0.0495965\n",
      "[400]\tvalid_0's rmse: 0.222447\tvalid_0's l2: 0.0494828\n",
      "[500]\tvalid_0's rmse: 0.222013\tvalid_0's l2: 0.0492899\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's rmse: 0.222002\tvalid_0's l2: 0.0492848\n"
     ]
    }
   ],
   "source": [
    "# LGBM model för radhus med randomized searchade parametrar\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Filtrera ut extremvärden\n",
    "lower_lgbm_radhus = dataframes[\"radhus\"][\"Pris\"].quantile(0.05)\n",
    "upper_lgbm_radhus = dataframes[\"radhus\"][\"Pris\"].quantile(0.95)\n",
    "\n",
    "df_filtered_lgbm_radhus = dataframes[\"radhus\"][\n",
    "    (dataframes[\"radhus\"][\"Pris\"] > lower_lgbm_radhus) & (dataframes[\"radhus\"][\"Pris\"] < upper_lgbm_radhus)].copy()\n",
    "\n",
    "# Features & target\n",
    "target_lgbm_radhus = \"Pris\"\n",
    "drop_cols_lgbm_radhus = [col for col in [\"Datum\", \"Bostadstyp\", \"Nyckel\", \"Totalarea\"] if col in df_filtered_lgbm_radhus.columns]\n",
    "\n",
    "X_lgbm_radhus = df_filtered_lgbm_radhus.drop(columns=[target_lgbm_radhus] + drop_cols_lgbm_radhus)\n",
    "y_lgbm_radhus = df_filtered_lgbm_radhus[target_lgbm_radhus]\n",
    "\n",
    "# Log-transformera target_lgbm_radhus\n",
    "y_lgbm_radhus_log = np.log1p(y_lgbm_radhus)\n",
    "\n",
    "\n",
    "# Gör kategoriska kolumner rätt\n",
    "# Konvertera textkolumner till \"category\" innan split\n",
    "for col in X_lgbm_radhus.select_dtypes(include=\"object\").columns:\n",
    "    X_lgbm_radhus[col] = X_lgbm_radhus[col].astype(\"category\")\n",
    "\n",
    "# Train/test split\n",
    "X_lgbm_radhus_train, X_lgbm_radhus_test, y_lgbm_radhus_train, y_lgbm_radhus_test = train_test_split(\n",
    "    X_lgbm_radhus, y_lgbm_radhus_log, test_size=0.2, random_state=11)\n",
    "\n",
    "# Lista index för kategoriska variabler\n",
    "cat_features_lgbm_radhus = [X_lgbm_radhus_train.columns.get_loc(col) for col in X_lgbm_radhus_train.select_dtypes(include=\"category\").columns]\n",
    "\n",
    "logging.info(f\"Kategoriska features: {[X_lgbm_radhus_train.columns[i] for i in cat_features_lgbm_radhus]}\")\n",
    "\n",
    "\n",
    "# LightGBM modell\n",
    "lgbm_model_radhus = LGBMRegressor(\n",
    "    n_estimators=500, # 1000\n",
    "    max_depth=10, # 12\n",
    "    learning_rate=0.03, # 0,01\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=1, # 0,6\n",
    "    reg_lambda=0, # 10\n",
    "    random_state=11,\n",
    "    n_jobs=-1)\n",
    "\n",
    "lgbm_model_radhus.fit(\n",
    "    X_lgbm_radhus_train, y_lgbm_radhus_train,\n",
    "    eval_set=[(X_lgbm_radhus_test, y_lgbm_radhus_test)],\n",
    "    eval_metric=\"rmse\",\n",
    "    categorical_feature=cat_features_lgbm_radhus,\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=100),\n",
    "        log_evaluation(period=100)])\n",
    "\n",
    "# Utvärdering\n",
    "# Prediktion på log-skalan\n",
    "y_lgbm_radhus_train_pred_log = lgbm_model_radhus.predict(X_lgbm_radhus_train)\n",
    "y_lgbm_radhus_test_pred_log = lgbm_model_radhus.predict(X_lgbm_radhus_test)\n",
    "\n",
    "# R² på log-skala\n",
    "r2_train_lgbm_radhus_log_lgbm_radhus = r2_score(y_lgbm_radhus_train, y_lgbm_radhus_train_pred_log)\n",
    "r2_test_lgbm_radhus_log_lgbm_radhus = r2_score(y_lgbm_radhus_test, y_lgbm_radhus_test_pred_log)\n",
    "\n",
    "logging.info(f\"Log-skala R² -> train: {r2_train_lgbm_radhus_log_lgbm_radhus:.3f}, test: {r2_test_lgbm_radhus_log_lgbm_radhus:.3f}\")\n",
    "\n",
    "# Back-transform till SEK\n",
    "y_lgbm_radhus_train_pred = np.expm1(y_lgbm_radhus_train_pred_log)\n",
    "y_lgbm_radhus_test_pred = np.expm1(y_lgbm_radhus_test_pred_log)\n",
    "\n",
    "y_lgbm_radhus_train_true = np.expm1(y_lgbm_radhus_train)\n",
    "y_lgbm_radhus_test_true = np.expm1(y_lgbm_radhus_test)\n",
    "\n",
    "# R² och RMSE i SEK\n",
    "r2_train_lgbm_radhus = r2_score(y_lgbm_radhus_train_true, y_lgbm_radhus_train_pred)\n",
    "r2_test_lgbm_radhus = r2_score(y_lgbm_radhus_test_true, y_lgbm_radhus_test_pred)\n",
    "\n",
    "rmse_train_lgbm_radhus = np.sqrt(mean_squared_error(y_lgbm_radhus_train_true, y_lgbm_radhus_train_pred))\n",
    "rmse_test_lgbm_radhus = np.sqrt(mean_squared_error(y_lgbm_radhus_test_true, y_lgbm_radhus_test_pred))\n",
    "\n",
    "logging.info(f\"LGBM tränad på radhus-data R² train: {r2_train_lgbm_radhus:.3f}, test: {r2_test_lgbm_radhus:.3f}\")\n",
    "logging.info(f\"LGBM tränad på radhus-data RMSE train: {rmse_train_lgbm_radhus:,.0f}, test: {rmse_test_lgbm_radhus:,.0f} kr\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump((lgbm_model_radhus, X_lgbm_radhus.columns), \"radhus_lgbm.pkl\")\n",
    "\n",
    "logging.info(\"Modellen är sparad som 'radhus_lgbm.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e03af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3204\n",
      "[LightGBM] [Info] Number of data points in the train set: 11822, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 15.100396\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3204\n",
      "[LightGBM] [Info] Number of data points in the train set: 11822, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 15.100396\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.230208\tvalid_0's l2: 0.0529957\n",
      "[200]\tvalid_0's rmse: 0.224041\tvalid_0's l2: 0.0501945\n",
      "[300]\tvalid_0's rmse: 0.222703\tvalid_0's l2: 0.0495965\n",
      "[400]\tvalid_0's rmse: 0.222447\tvalid_0's l2: 0.0494828\n",
      "[500]\tvalid_0's rmse: 0.222013\tvalid_0's l2: 0.0492899\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's rmse: 0.222002\tvalid_0's l2: 0.0492848\n"
     ]
    }
   ],
   "source": [
    "# Randomized search LGBM radhus\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Definiera parameterutrymme\n",
    "param_dist = {\n",
    "    \"n_estimators\": [500, 1000, 2000, 3000],\n",
    "    \"max_depth\": [6, 8, 10, 12, -1],   # -1 = ingen begränsning\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"reg_lambda\": [0, 1, 5, 10]}\n",
    "\n",
    "# Basmodell\n",
    "lgbm_base_radhus = LGBMRegressor(random_state=11, n_jobs=-1)\n",
    "\n",
    "# Randomized Search\n",
    "random_search_lgbm_radhus = RandomizedSearchCV(\n",
    "    estimator=lgbm_base_radhus,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,   # antal kombinationer att testa\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=11)\n",
    "\n",
    "logging.info(\"Startar RandomizedSearchCV för LGBM (radhus)...\")\n",
    "\n",
    "# Kör sökning\n",
    "random_search_lgbm_radhus.fit(\n",
    "    X_lgbm_radhus_train, y_lgbm_radhus_train,\n",
    "    categorical_feature=cat_features_lgbm_radhus)\n",
    "\n",
    "# Bästa parametrar\n",
    "best_params_radhus = random_search_lgbm_radhus.best_params_\n",
    "best_score_radhus = random_search_lgbm_radhus.best_score_\n",
    "\n",
    "logging.info(f\"Bästa LGBM-parametrar (radhus): {best_params_radhus}\")\n",
    "logging.info(f\"Bästa CV-score (RMSE, log-skala): {best_score_radhus:.4f}\")\n",
    "\n",
    "# Träna om bästa modellen på hela träningsdatan\n",
    "best_lgbm_radhus = random_search_lgbm_radhus.best_estimator_\n",
    "best_lgbm_radhus.fit(\n",
    "    X_lgbm_radhus_train, y_lgbm_radhus_train,\n",
    "    eval_set=[(X_lgbm_radhus_test, y_lgbm_radhus_test)],\n",
    "    eval_metric=\"rmse\",\n",
    "    categorical_feature=cat_features_lgbm_radhus,\n",
    "    callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=100)])\n",
    "\n",
    "# Utvärdera på test\n",
    "y_test_pred_log = best_lgbm_radhus.predict(X_lgbm_radhus_test)\n",
    "y_test_pred = np.expm1(y_test_pred_log)\n",
    "y_test_true = np.expm1(y_lgbm_radhus_test)\n",
    "\n",
    "r2_test = r2_score(y_test_true, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_true, y_test_pred))\n",
    "\n",
    "logging.info(f\"Bästa LGBM R² test (radhus): {r2_test:.3f}\")\n",
    "logging.info(f\"Bästa LGBM RMSE test (radhus): {rmse_test:,.0f} kr\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump((best_lgbm_radhus, X_lgbm_radhus.columns), \"radhus_lgbm_best.pkl\")\n",
    "logging.info(\"Bästa modellen är sparad som 'radhus_lgbm_best.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
